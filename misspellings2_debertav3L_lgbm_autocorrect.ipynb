{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/CommonLit-Evaluate-Student-Summaries/blob/main/misspellings2_debertav3L_lgbm_autocorrect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9FkXnqfL4Vd0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_917tB4eGO",
        "outputId": "c18f04a3-e5e4-4136-c04a-0c2ee519eefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7hSZqxM34hSK"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  !mkdir -p /root/.kaggle\n",
        "  !cp /content/drive/MyDrive/Kaggle/kaggle.json  /root/.kaggle/\n",
        "  !chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgkYiHO4qhy",
        "outputId": "89741919-6965-43e4-ea18-36cfce51d437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install kaggle\n",
        "  !apt install unzip\n",
        "  !mkdir input output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5vNe0z44tmh",
        "outputId": "adfd49e4-6275-48b4-f1ba-275e9b0ad333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            " 95% 1.00M/1.05M [00:00<00:00, 1.08MB/s]\n",
            "100% 1.05M/1.05M [00:00<00:00, 1.12MB/s]\n",
            "Archive:  commonlit-evaluate-student-summaries.zip\n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_train.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/sample_submission.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_train.csv  \n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !kaggle competitions download -c commonlit-evaluate-student-summaries\n",
        "  !unzip -o commonlit-evaluate-student-summaries.zip -d input/commonlit-evaluate-student-summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aCDfcTM6l1n",
        "outputId": "d1a21c36-dc7d-4a50-fa27-3241ed08d4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting autocorrect==2.6\n",
            "  Downloading autocorrect-2.6.0.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.6/622.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.0-py3-none-any.whl size=622231 sha256=189fbbdf7757e8d9cb40ec4e044672601542555a2b54cfae6161ec526ca2187f\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/66/c6/7470703fc0cd7739a9bbfd7bf8d2b42b2df4eeeca5be85ad7a\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.0\n",
            "Collecting pyspellchecker==0.7.2\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install transformers\n",
        "  !pip install datasets\n",
        "  !pip install sentencepiece\n",
        "  !pip install autocorrect==2.6\n",
        "  !pip install pyspellchecker==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owJ9XYkWC33k",
        "outputId": "76008ebd-74bc-4387-dac6-bd8a840287f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-9vy0mi49\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-9vy0mi49\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 5ae611118057232f441055f7ef9ba0b0f2b8d533\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.24.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.24.0.dev0-py3-none-any.whl size=258568 sha256=12437733acab30fee072376d52c3811f35eb952c51df8611bef95436d5b3a38b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9fjqwuf/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.0.dev0\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_dxr0ku-Vw8"
      },
      "source": [
        "# ここでランタイムの再起動が必要！！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtdyP9QL7hFs",
        "outputId": "7e44775c-ea9c-4c1d-fd55-cc8ed42ff9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True\n",
        "\n",
        "if is_colab:\n",
        "  %cd output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "357f0fac4f5f429eb825e59dc607af19",
            "c740bd8269aa4b34a83e0d5d1c7a4877",
            "2f9da7ec302248ae8b89900c6b4fc3be",
            "7712322fea9440de8ab21e078e3129f8",
            "d82960fab7a348ac8e8240f7726cc8d4",
            "7870491a91404534a57e8a14efb0d2b1",
            "81620c8c3d7e462592d3e0603f4e1135",
            "5b9175341bee4aaba32e42d8ac778e64",
            "c7a21ac5c4eb4fc8913987fd7c7e9baf",
            "192544ae69824dcda0b5bfe3d161687b",
            "3ed97600141d4818b4fc6e474a336d43",
            "c3661842a2de42d2b559e0aed6009032",
            "c4bfe2dc9249482b932deff8dbdc78a4",
            "7e98de290a7d4bdc9856ead361050e9f",
            "63b6381122a64466b8de6312ad9111c4",
            "dae6ae07a4ba4125a8c060eb9704df32",
            "d6a94e1414e34ac7b3206eea841db0d2",
            "ba3d9c1859eb43ccb1acd6e1bb47e8f5",
            "f33aedebd0fd45bd8aba9e9db400baca",
            "d879293fa270435cbef2223a596d34d1",
            "d73c5dfd500c4defacbd74c8ac86855f",
            "958a72c0d3fa4a8abac85762aad96779",
            "f5a3857f4a9546babbe476d9a0e59301",
            "c5835b46278a441ba03659fc29c85d43",
            "6be3769bd0f54718aa6d4438b9792962",
            "5a9ec6f594084459a3551ebbf945c627",
            "2a031e4f52af408780c7bcf1a80dd04f",
            "29a214e7fb714b4a94ed2500ed037392",
            "ee96d111751a4d1d953a9f10b3b742df",
            "51062018306e49028985d346a0a13cca",
            "c9a397403fc74322bc334bd6b60d9c29",
            "09a377c9482641d08bd13ddbd144122b",
            "c73cf5a130aa45e5bb33b8b06312b6bd",
            "458c54163df44c4386f2b30e2db12288",
            "71573d052959407e8371cc7d1c4a6100",
            "c92534e1fc894226981376968ef66bf7",
            "1e12b878dc7c4768adaebd382bf9d796",
            "f1c9cb4f422f499481b8d27515ce0932",
            "30a60bfc2f5d4b80b38849ac6fb15e26",
            "cc6a70f34a40442f9ba0113e02ecc59c",
            "92b9965268b54a43a2d71bade997a88f",
            "c3b6482054ab4c67bdc399f2a6bd773a",
            "dbcbf045dc154a89a0980c4e648e8f28",
            "d07065c2284a467c9460a30300f706db"
          ]
        },
        "id": "EdROKpaD7DWX",
        "outputId": "b189463c-f67e-4a84-d930-56de1e724af4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "357f0fac4f5f429eb825e59dc607af19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3661842a2de42d2b559e0aed6009032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5a3857f4a9546babbe476d9a0e59301"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "458c54163df44c4386f2b30e2db12288"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "  model_name = \"microsoft/deberta-v3-large\"\n",
        "  # model_name = \"roberta-base\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  hidden_dropout_prob=0.007\n",
        "  attention_probs_dropout_prob=0.007\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "  model_dir = \"../input/another-bert\"\n",
        "  model.save_pretrained(model_dir)\n",
        "  tokenizer.save_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BFTn4SLsclH",
        "outputId": "9749649e-76aa-470e-86a9-99df3cf1ff2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deberta.embeddings.word_embeddings.weight True\n",
            "deberta.embeddings.LayerNorm.weight True\n",
            "deberta.embeddings.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.0.attention.output.dense.weight True\n",
            "deberta.encoder.layer.0.attention.output.dense.bias True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.intermediate.dense.weight True\n",
            "deberta.encoder.layer.0.intermediate.dense.bias True\n",
            "deberta.encoder.layer.0.output.dense.weight True\n",
            "deberta.encoder.layer.0.output.dense.bias True\n",
            "deberta.encoder.layer.0.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.1.attention.output.dense.weight True\n",
            "deberta.encoder.layer.1.attention.output.dense.bias True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.intermediate.dense.weight True\n",
            "deberta.encoder.layer.1.intermediate.dense.bias True\n",
            "deberta.encoder.layer.1.output.dense.weight True\n",
            "deberta.encoder.layer.1.output.dense.bias True\n",
            "deberta.encoder.layer.1.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.2.attention.output.dense.weight True\n",
            "deberta.encoder.layer.2.attention.output.dense.bias True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.intermediate.dense.weight True\n",
            "deberta.encoder.layer.2.intermediate.dense.bias True\n",
            "deberta.encoder.layer.2.output.dense.weight True\n",
            "deberta.encoder.layer.2.output.dense.bias True\n",
            "deberta.encoder.layer.2.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.3.attention.output.dense.weight True\n",
            "deberta.encoder.layer.3.attention.output.dense.bias True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.intermediate.dense.weight True\n",
            "deberta.encoder.layer.3.intermediate.dense.bias True\n",
            "deberta.encoder.layer.3.output.dense.weight True\n",
            "deberta.encoder.layer.3.output.dense.bias True\n",
            "deberta.encoder.layer.3.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.4.attention.output.dense.weight True\n",
            "deberta.encoder.layer.4.attention.output.dense.bias True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.intermediate.dense.weight True\n",
            "deberta.encoder.layer.4.intermediate.dense.bias True\n",
            "deberta.encoder.layer.4.output.dense.weight True\n",
            "deberta.encoder.layer.4.output.dense.bias True\n",
            "deberta.encoder.layer.4.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.5.attention.output.dense.weight True\n",
            "deberta.encoder.layer.5.attention.output.dense.bias True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.intermediate.dense.weight True\n",
            "deberta.encoder.layer.5.intermediate.dense.bias True\n",
            "deberta.encoder.layer.5.output.dense.weight True\n",
            "deberta.encoder.layer.5.output.dense.bias True\n",
            "deberta.encoder.layer.5.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.6.attention.output.dense.weight True\n",
            "deberta.encoder.layer.6.attention.output.dense.bias True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.intermediate.dense.weight True\n",
            "deberta.encoder.layer.6.intermediate.dense.bias True\n",
            "deberta.encoder.layer.6.output.dense.weight True\n",
            "deberta.encoder.layer.6.output.dense.bias True\n",
            "deberta.encoder.layer.6.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.7.attention.output.dense.weight True\n",
            "deberta.encoder.layer.7.attention.output.dense.bias True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.intermediate.dense.weight True\n",
            "deberta.encoder.layer.7.intermediate.dense.bias True\n",
            "deberta.encoder.layer.7.output.dense.weight True\n",
            "deberta.encoder.layer.7.output.dense.bias True\n",
            "deberta.encoder.layer.7.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.8.attention.output.dense.weight True\n",
            "deberta.encoder.layer.8.attention.output.dense.bias True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.intermediate.dense.weight True\n",
            "deberta.encoder.layer.8.intermediate.dense.bias True\n",
            "deberta.encoder.layer.8.output.dense.weight True\n",
            "deberta.encoder.layer.8.output.dense.bias True\n",
            "deberta.encoder.layer.8.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.9.attention.output.dense.weight True\n",
            "deberta.encoder.layer.9.attention.output.dense.bias True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.intermediate.dense.weight True\n",
            "deberta.encoder.layer.9.intermediate.dense.bias True\n",
            "deberta.encoder.layer.9.output.dense.weight True\n",
            "deberta.encoder.layer.9.output.dense.bias True\n",
            "deberta.encoder.layer.9.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.10.attention.output.dense.weight True\n",
            "deberta.encoder.layer.10.attention.output.dense.bias True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.intermediate.dense.weight True\n",
            "deberta.encoder.layer.10.intermediate.dense.bias True\n",
            "deberta.encoder.layer.10.output.dense.weight True\n",
            "deberta.encoder.layer.10.output.dense.bias True\n",
            "deberta.encoder.layer.10.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.11.attention.output.dense.weight True\n",
            "deberta.encoder.layer.11.attention.output.dense.bias True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.intermediate.dense.weight True\n",
            "deberta.encoder.layer.11.intermediate.dense.bias True\n",
            "deberta.encoder.layer.11.output.dense.weight True\n",
            "deberta.encoder.layer.11.output.dense.bias True\n",
            "deberta.encoder.layer.11.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.12.attention.output.dense.weight True\n",
            "deberta.encoder.layer.12.attention.output.dense.bias True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.intermediate.dense.weight True\n",
            "deberta.encoder.layer.12.intermediate.dense.bias True\n",
            "deberta.encoder.layer.12.output.dense.weight True\n",
            "deberta.encoder.layer.12.output.dense.bias True\n",
            "deberta.encoder.layer.12.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.13.attention.output.dense.weight True\n",
            "deberta.encoder.layer.13.attention.output.dense.bias True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.intermediate.dense.weight True\n",
            "deberta.encoder.layer.13.intermediate.dense.bias True\n",
            "deberta.encoder.layer.13.output.dense.weight True\n",
            "deberta.encoder.layer.13.output.dense.bias True\n",
            "deberta.encoder.layer.13.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.14.attention.output.dense.weight True\n",
            "deberta.encoder.layer.14.attention.output.dense.bias True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.intermediate.dense.weight True\n",
            "deberta.encoder.layer.14.intermediate.dense.bias True\n",
            "deberta.encoder.layer.14.output.dense.weight True\n",
            "deberta.encoder.layer.14.output.dense.bias True\n",
            "deberta.encoder.layer.14.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.15.attention.output.dense.weight True\n",
            "deberta.encoder.layer.15.attention.output.dense.bias True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.intermediate.dense.weight True\n",
            "deberta.encoder.layer.15.intermediate.dense.bias True\n",
            "deberta.encoder.layer.15.output.dense.weight True\n",
            "deberta.encoder.layer.15.output.dense.bias True\n",
            "deberta.encoder.layer.15.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.16.attention.output.dense.weight True\n",
            "deberta.encoder.layer.16.attention.output.dense.bias True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.intermediate.dense.weight True\n",
            "deberta.encoder.layer.16.intermediate.dense.bias True\n",
            "deberta.encoder.layer.16.output.dense.weight True\n",
            "deberta.encoder.layer.16.output.dense.bias True\n",
            "deberta.encoder.layer.16.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.17.attention.output.dense.weight True\n",
            "deberta.encoder.layer.17.attention.output.dense.bias True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.intermediate.dense.weight True\n",
            "deberta.encoder.layer.17.intermediate.dense.bias True\n",
            "deberta.encoder.layer.17.output.dense.weight True\n",
            "deberta.encoder.layer.17.output.dense.bias True\n",
            "deberta.encoder.layer.17.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.18.attention.output.dense.weight True\n",
            "deberta.encoder.layer.18.attention.output.dense.bias True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.intermediate.dense.weight True\n",
            "deberta.encoder.layer.18.intermediate.dense.bias True\n",
            "deberta.encoder.layer.18.output.dense.weight True\n",
            "deberta.encoder.layer.18.output.dense.bias True\n",
            "deberta.encoder.layer.18.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.19.attention.output.dense.weight True\n",
            "deberta.encoder.layer.19.attention.output.dense.bias True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.intermediate.dense.weight True\n",
            "deberta.encoder.layer.19.intermediate.dense.bias True\n",
            "deberta.encoder.layer.19.output.dense.weight True\n",
            "deberta.encoder.layer.19.output.dense.bias True\n",
            "deberta.encoder.layer.19.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.20.attention.output.dense.weight True\n",
            "deberta.encoder.layer.20.attention.output.dense.bias True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.intermediate.dense.weight True\n",
            "deberta.encoder.layer.20.intermediate.dense.bias True\n",
            "deberta.encoder.layer.20.output.dense.weight True\n",
            "deberta.encoder.layer.20.output.dense.bias True\n",
            "deberta.encoder.layer.20.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.21.attention.output.dense.weight True\n",
            "deberta.encoder.layer.21.attention.output.dense.bias True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.intermediate.dense.weight True\n",
            "deberta.encoder.layer.21.intermediate.dense.bias True\n",
            "deberta.encoder.layer.21.output.dense.weight True\n",
            "deberta.encoder.layer.21.output.dense.bias True\n",
            "deberta.encoder.layer.21.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.22.attention.output.dense.weight True\n",
            "deberta.encoder.layer.22.attention.output.dense.bias True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.intermediate.dense.weight True\n",
            "deberta.encoder.layer.22.intermediate.dense.bias True\n",
            "deberta.encoder.layer.22.output.dense.weight True\n",
            "deberta.encoder.layer.22.output.dense.bias True\n",
            "deberta.encoder.layer.22.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.23.attention.output.dense.weight True\n",
            "deberta.encoder.layer.23.attention.output.dense.bias True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.intermediate.dense.weight True\n",
            "deberta.encoder.layer.23.intermediate.dense.bias True\n",
            "deberta.encoder.layer.23.output.dense.weight True\n",
            "deberta.encoder.layer.23.output.dense.bias True\n",
            "deberta.encoder.layer.23.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.output.LayerNorm.bias True\n",
            "deberta.encoder.rel_embeddings.weight True\n",
            "deberta.encoder.LayerNorm.weight True\n",
            "deberta.encoder.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        " # You can confirm which layers have been frozen and see the whole layer struct of the model\n",
        " for n, p in model.named_parameters():\n",
        "    print(n, p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "edsSr0fIs2y2"
      },
      "outputs": [],
      "source": [
        "def top_half_layer_freeze(model):\n",
        "    for i in range(0,6,1):\n",
        "        for n,p in model.named_parameters():\n",
        "            if f'encoder.layer.{i}.' in n:\n",
        "                p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3OcffOfUs4OC"
      },
      "outputs": [],
      "source": [
        "top_half_layer_freeze(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMpRe4l5AO_P",
        "outputId": "ccd62b2f-23fd-4d04-ffa0-a4feee226c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnE6iEp4RXS"
      },
      "source": [
        "# Notes\n",
        "This is a slightly tuned version of @nogawanogawa 's work and I have also converted his messages to english here you can find his notebook here https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-spell-autocorrect please give him kudos for sharing his efforts\n",
        "\n",
        "### Things I would expect there to be a number of things that will allow this model to preform better outside of just strategy and more data. I would imagine there are a few more tuning parameters that could help this model go a long way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this notebook a combonation of Deberta and LGBM is used, pyspellchecker is also used in order to correct some of the spelling mistakes that are discussed in the discussions tab\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "[my previous notebook](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering)\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "\n",
        "The primary goal of this notebook is to enhance the overall score by honing in on the issue of \"misspellings.\"\n",
        "\n",
        "## Main Concept\n",
        "\n",
        "The Transformers model I'm currently utilizing, Deberta, is pretrained on \"correct sentences.\" However, if I were to train and input it with sentences containing misspellings, Deberta's ability to understand meaning might be compromised.\n",
        "\n",
        "From a human evaluator's perspective, detecting misspellings would prompt deductions in scores. After discreetly rectifying the misspelled words, I'd proceed to evaluate other textual facets. If we assume the scoring process aligns with this approach, it's conceivable that tallying and **correcting** misspellings before feeding text into Deberta could enable the model to aptly capture features beyond just misspellings.\n",
        "\n",
        "In this notebook, I will embark on the journey of auto-correcting misspelled words before inputting them into Deberta. The aim is to evaluate the model's performance by distinctly isolating misspellings from other aspects.\n",
        "\n",
        "### Feature Engineering\n",
        "\n",
        "I intend to largely retain the same features as before:\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - Count\n",
        "  - Ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - Spelling: pyspellchecker\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "I plan to construct a model with the architecture depicted in the following diagram. For the input to Deberta (`text`), I will pre-process by correcting any misspellings. In other aspects of feature engineering, I will utilize the `text` as is.\n",
        "\n",
        "### References\n",
        "\n",
        "- https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941\n",
        "\n",
        "### My previous notebooks\n",
        "\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-with-llama2-example\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X3e8TQJd4RXU"
      },
      "outputs": [],
      "source": [
        "if not is_colab :\n",
        "  !pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
        "  !pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vkGQJ0tu4RXV"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset,load_dataset, load_from_disk\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric, disable_progress_bar\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "from autocorrect import Speller\n",
        "from spellchecker import SpellChecker\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTSJWXAjvRa",
        "outputId": "b19d2c7a-bfb5-42d7-cd79-3073b44d859f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu= 8\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "cpu_num = multiprocessing.cpu_count()\n",
        "print(\"cpu=\", cpu_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jwl4vqgbjyBh"
      },
      "outputs": [],
      "source": [
        "seed_base = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y-pPPJ3a4RXV"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=seed_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jfBN_xxH4RXW"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name=\"another-bert\"\n",
        "    learning_rate=1.5e-5\n",
        "    weight_decay=0.02\n",
        "    hidden_dropout_prob=0.007\n",
        "    attention_probs_dropout_prob=0.007\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=3\n",
        "\n",
        "    random_seed=seed_base\n",
        "    save_steps=100\n",
        "    max_length=512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzSk2kRA4RXW"
      },
      "source": [
        "## Dataload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B3nYzKoi4RXW"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"../input/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2huhIeJ4RXW"
      },
      "source": [
        "## Preprocess\n",
        "\n",
        "[Using features]\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - count\n",
        "  - ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - spelling: pyspellchecker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y7F-j8-I_e18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hESbPb6N4RXW"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                ) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.twd = TreebankWordDetokenizer()\n",
        "        self.STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
        "        self.speller = Speller(lang='en')\n",
        "        self.spellchecker = SpellChecker()\n",
        "\n",
        "    def word_overlap_count(self, row):\n",
        "        \"\"\" intersection(prompt_text, text) \"\"\"\n",
        "        def check_is_stop_word(word):\n",
        "            return word in self.STOP_WORDS\n",
        "\n",
        "        prompt_words = row['prompt_tokens']\n",
        "        summary_words = row['summary_tokens']\n",
        "        if self.STOP_WORDS:\n",
        "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
        "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
        "        return len(set(prompt_words).intersection(set(summary_words)))\n",
        "\n",
        "    def ngrams(self, token, n):\n",
        "        # Use the zip function to help us generate n-grams\n",
        "        # Concatentate the tokens into ngrams and return\n",
        "        ngrams = zip(*[token[i:] for i in range(n)])\n",
        "        return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
        "        # Tokenize the original text and summary into words\n",
        "        original_tokens = row['prompt_tokens']\n",
        "        summary_tokens = row['summary_tokens']\n",
        "\n",
        "        # Generate n-grams for the original text and summary\n",
        "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
        "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
        "\n",
        "        # Calculate the number of common n-grams\n",
        "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
        "        return len(common_ngrams)\n",
        "\n",
        "    def ner_overlap_count(self, row, mode:str):\n",
        "        model = self.spacy_ner_model\n",
        "        def clean_ners(ner_list):\n",
        "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
        "        prompt = model(row['prompt_text'])\n",
        "        summary = model(row['text'])\n",
        "\n",
        "        if \"spacy\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
        "        elif \"stanza\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
        "        else:\n",
        "            raise Exception(\"Model not supported\")\n",
        "\n",
        "        prompt_ner = clean_ners(prompt_ner)\n",
        "        summary_ner = clean_ners(summary_ner)\n",
        "\n",
        "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
        "\n",
        "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
        "\n",
        "        if mode == \"train\":\n",
        "            return ner_dict\n",
        "        elif mode == \"test\":\n",
        "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
        "\n",
        "\n",
        "    def quotes_count(self, row):\n",
        "        summary = row['text']\n",
        "        text = row['prompt_text']\n",
        "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
        "        if len(quotes_from_summary)>0:\n",
        "            return [quote in text for quote in quotes_from_summary].count(True)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def spelling(self, text):\n",
        "\n",
        "        wordlist=text.split()\n",
        "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
        "\n",
        "        return amount_miss\n",
        "\n",
        "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
        "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
        "        self.spellchecker.word_frequency.load_words(tokens)\n",
        "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
        "\n",
        "    def run(self,\n",
        "            prompts: pd.DataFrame,\n",
        "            summaries:pd.DataFrame,\n",
        "            mode:str\n",
        "        ) -> pd.DataFrame:\n",
        "\n",
        "        # before merge preprocess\n",
        "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        # Add prompt tokens into spelling checker dictionary\n",
        "        prompts[\"prompt_tokens\"].apply(\n",
        "            lambda x: self.add_spelling_dictionary(x)\n",
        "        )\n",
        "\n",
        "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "        # fix misspelling\n",
        "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
        "            lambda x: self.speller(x)\n",
        "        )\n",
        "\n",
        "        # count misspelling\n",
        "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
        "\n",
        "        # merge prompts and summaries\n",
        "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
        "\n",
        "        # after merge preprocess\n",
        "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
        "\n",
        "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
        "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence,args=(2,), axis=1\n",
        "        )\n",
        "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
        "\n",
        "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence, args=(3,), axis=1\n",
        "        )\n",
        "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
        "\n",
        "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
        "\n",
        "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
        "\n",
        "preprocessor = Preprocessor(model_name=CFG.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "CJEL4wDV4RXX",
        "outputId": "c4dbb326-2bde-4011-f0ad-22e2887f331f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7165/7165 [06:46<00:00, 17.61it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 7699.24it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 9164.79it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4701.40it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4385.13it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 83709.90it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7426.83it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 9909.76it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 2025.74it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3876.44it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3985.09it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 4071.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  \n",
              "0             0  \n",
              "1             0  \n",
              "2             2  \n",
              "3             0  \n",
              "4             4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54a6f96a-1fe3-481f-9e3e-0ea8f77d28cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54a6f96a-1fe3-481f-9e3e-0ea8f77d28cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54a6f96a-1fe3-481f-9e3e-0ea8f77d28cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54a6f96a-1fe3-481f-9e3e-0ea8f77d28cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e6524f9-db58-4fbc-8207-1a4ec17bcdae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e6524f9-db58-4fbc-8207-1a4ec17bcdae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e6524f9-db58-4fbc-8207-1a4ec17bcdae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
        "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kqEJ3DWX4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'wb') as f:\n",
        "    pickle.dump(train, f)\n",
        "    pickle.dump(test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dxMtKG9l4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'rb') as f:\n",
        "    train = pickle.load(f)\n",
        "    test = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qCo_NEhg6SEb"
      },
      "outputs": [],
      "source": [
        "# train = train[:512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "YavvVjbl4RXX",
        "outputId": "defdd4c6-2516-44af-bd46-b6ec24659fcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  fold  \n",
              "0             0   3.0  \n",
              "1             0   2.0  \n",
              "2             2   1.0  \n",
              "3             0   1.0  \n",
              "4             4   3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ba9a05-5543-44cf-9911-08da0ac98792\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ba9a05-5543-44cf-9911-08da0ac98792')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22ba9a05-5543-44cf-9911-08da0ac98792 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22ba9a05-5543-44cf-9911-08da0ac98792');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5529ed9-f49b-48d9-b7a5-629afad733de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5529ed9-f49b-48d9-b7a5-629afad733de')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5529ed9-f49b-48d9-b7a5-629afad733de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ40iLxj4RXX"
      },
      "source": [
        "## Model Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C6JS7cYm4RXX"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_BYbqcT4RXX"
      },
      "source": [
        "## Deberta Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ne-jnegYEw4C"
      },
      "outputs": [],
      "source": [
        "class ContentScoreRegressor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                model_dir: str,\n",
        "                target: str,\n",
        "                hidden_dropout_prob: float,\n",
        "                attention_probs_dropout_prob: float,\n",
        "                max_length: int,\n",
        "                ):\n",
        "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
        "        self.input_col = \"input\"\n",
        "\n",
        "        self.text_cols = [self.input_col]\n",
        "        self.target = target\n",
        "        self.target_cols = [target]\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.model_dir = model_dir\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.model_config = AutoConfig.from_pretrained(f\"../input/{model_name}\")\n",
        "\n",
        "        self.model_config.update({\n",
        "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
        "            \"num_labels\": 1,\n",
        "            \"problem_type\": \"regression\",\n",
        "        })\n",
        "\n",
        "        seed_everything(seed=42)\n",
        "\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=self.tokenizer\n",
        "        )\n",
        "\n",
        "\n",
        "    def tokenize_function(self, examples: pd.DataFrame):\n",
        "        labels = [examples[self.target]]\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return {\n",
        "            **tokenized,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return tokenized\n",
        "\n",
        "    def train(self,\n",
        "            fold: int,\n",
        "            train_df: pd.DataFrame,\n",
        "            valid_df: pd.DataFrame,\n",
        "            batch_size: int,\n",
        "            learning_rate: float,\n",
        "            weight_decay: float,\n",
        "            num_train_epochs: float,\n",
        "            save_steps: int,\n",
        "        ) -> None:\n",
        "        \"\"\"fine-tuning\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        train_df[self.input_col] = (\n",
        "                    train_df[\"prompt_title\"] + sep\n",
        "                    + train_df[\"prompt_question\"] + sep\n",
        "                    + train_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + train_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        valid_df[self.input_col] = (\n",
        "                    valid_df[\"prompt_title\"] + sep\n",
        "                    + valid_df[\"prompt_question\"] + sep\n",
        "                    + valid_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + valid_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        train_df = train_df[[self.input_col] + self.target_cols]\n",
        "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
        "            f\"../input/{self.model_name}\",\n",
        "            config=self.model_config,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        top_half_layer_freeze(model_content)\n",
        "\n",
        "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
        "\n",
        "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
        "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
        "\n",
        "        # eg. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            load_best_model_at_end=True, # select best model\n",
        "            learning_rate=learning_rate,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=4,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            report_to='none',\n",
        "            greater_is_better=False,\n",
        "            save_strategy=\"steps\",\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=save_steps,\n",
        "            save_steps=save_steps,\n",
        "            metric_for_best_model=\"rmse\",\n",
        "            save_total_limit=1,\n",
        "            fp16=True,\n",
        "            warmup_steps = 100,\n",
        "            gradient_accumulation_steps = 4,\n",
        "            dataloader_num_workers = cpu_num,\n",
        "            )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model_content,\n",
        "            args=training_args,\n",
        "            train_dataset=train_tokenized_datasets,\n",
        "            eval_dataset=val_tokenized_datasets,\n",
        "            tokenizer=self.tokenizer,\n",
        "            compute_metrics=compute_metrics,\n",
        "            data_collator=self.data_collator\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        shutil.rmtree(self.model_dir)\n",
        "\n",
        "        model_content.save_pretrained(self.model_dir)\n",
        "        self.tokenizer.save_pretrained(self.model_dir)\n",
        "\n",
        "\n",
        "    def predict(self,\n",
        "                test_df: pd.DataFrame,\n",
        "                fold: int,\n",
        "               ):\n",
        "        \"\"\"predict content score\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        in_text = (\n",
        "                    test_df[\"prompt_title\"] + sep\n",
        "                    + test_df[\"prompt_question\"] + sep\n",
        "                    + test_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + test_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "        test_df[self.input_col] = in_text\n",
        "\n",
        "        test_ = test_df[[self.input_col]]\n",
        "\n",
        "        test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n",
        "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
        "        model_content.eval()\n",
        "\n",
        "        # e.g. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = 4,\n",
        "            dataloader_drop_last = False,\n",
        "        )\n",
        "\n",
        "        # init trainer\n",
        "        infer_content = Trainer(\n",
        "                      model = model_content,\n",
        "                      tokenizer=self.tokenizer,\n",
        "                      data_collator=self.data_collator,\n",
        "                      args = test_args)\n",
        "\n",
        "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7-yViAlt4RXX"
      },
      "outputs": [],
      "source": [
        "def train_by_fold(\n",
        "        train_df: pd.DataFrame,\n",
        "        model_name: str,\n",
        "        target:str,\n",
        "        save_each_model: bool,\n",
        "        n_splits: int,\n",
        "        batch_size: int,\n",
        "        learning_rate: int,\n",
        "        hidden_dropout_prob: float,\n",
        "        attention_probs_dropout_prob: float,\n",
        "        weight_decay: float,\n",
        "        num_train_epochs: int,\n",
        "        save_steps: int,\n",
        "        max_length:int\n",
        "    ):\n",
        "\n",
        "    # delete old model files\n",
        "    if os.path.exists(model_name):\n",
        "        shutil.rmtree(model_name)\n",
        "\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        train_data = train_df[train_df[\"fold\"] != fold]\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        csr.train(\n",
        "            fold=fold,\n",
        "            train_df=train_data,\n",
        "            valid_df=valid_data,\n",
        "            batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=weight_decay,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            save_steps=save_steps,\n",
        "        )\n",
        "\n",
        "def validate(\n",
        "    train_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict oof data\"\"\"\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=valid_data,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
        "\n",
        "    return train_df\n",
        "\n",
        "def predict(\n",
        "    test_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ):\n",
        "    \"\"\"predict using mean folds\"\"\"\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=test_df,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
        "\n",
        "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
        "\n",
        "    return test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8twHE2C44RXY",
        "outputId": "4c48a1c5-2ec1-45b9-f3ea-f9c14a3f10b8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 52:27, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.457434</td>\n",
              "      <td>0.676338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.409868</td>\n",
              "      <td>0.640210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.217407</td>\n",
              "      <td>0.466269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.155083</td>\n",
              "      <td>0.393806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.318600</td>\n",
              "      <td>0.528165</td>\n",
              "      <td>0.726750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.318600</td>\n",
              "      <td>0.242365</td>\n",
              "      <td>0.492306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.318600</td>\n",
              "      <td>0.184758</td>\n",
              "      <td>0.429835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.318600</td>\n",
              "      <td>0.239193</td>\n",
              "      <td>0.489074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.318600</td>\n",
              "      <td>0.231287</td>\n",
              "      <td>0.480923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.296447</td>\n",
              "      <td>0.544469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.257617</td>\n",
              "      <td>0.507559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.372035</td>\n",
              "      <td>0.609947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.222915</td>\n",
              "      <td>0.472139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.263503</td>\n",
              "      <td>0.513325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.086500</td>\n",
              "      <td>0.270070</td>\n",
              "      <td>0.519683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.086500</td>\n",
              "      <td>0.297514</td>\n",
              "      <td>0.545448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.086500</td>\n",
              "      <td>0.212810</td>\n",
              "      <td>0.461313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.086500</td>\n",
              "      <td>0.288178</td>\n",
              "      <td>0.536822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.086500</td>\n",
              "      <td>0.264739</td>\n",
              "      <td>0.514528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.276905</td>\n",
              "      <td>0.526218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.273631</td>\n",
              "      <td>0.523097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 54:40, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.272620</td>\n",
              "      <td>0.522130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.316640</td>\n",
              "      <td>0.562708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.330209</td>\n",
              "      <td>0.574638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369248</td>\n",
              "      <td>0.607658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.338661</td>\n",
              "      <td>0.581946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.317887</td>\n",
              "      <td>0.563815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.320549</td>\n",
              "      <td>0.566171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.375114</td>\n",
              "      <td>0.612466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.257973</td>\n",
              "      <td>0.507911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.240845</td>\n",
              "      <td>0.490760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.230688</td>\n",
              "      <td>0.480300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.246417</td>\n",
              "      <td>0.496404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.262073</td>\n",
              "      <td>0.511930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.227064</td>\n",
              "      <td>0.476512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.241385</td>\n",
              "      <td>0.491309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.259103</td>\n",
              "      <td>0.509021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.269386</td>\n",
              "      <td>0.519024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.266301</td>\n",
              "      <td>0.516044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.233641</td>\n",
              "      <td>0.483365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.245185</td>\n",
              "      <td>0.495162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.242555</td>\n",
              "      <td>0.492498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 54:38, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.286001</td>\n",
              "      <td>0.534791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.278820</td>\n",
              "      <td>0.528034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204197</td>\n",
              "      <td>0.451882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.232410</td>\n",
              "      <td>0.482089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.329200</td>\n",
              "      <td>0.233158</td>\n",
              "      <td>0.482864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.329200</td>\n",
              "      <td>0.267974</td>\n",
              "      <td>0.517662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.329200</td>\n",
              "      <td>0.291038</td>\n",
              "      <td>0.539480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.329200</td>\n",
              "      <td>0.182689</td>\n",
              "      <td>0.427422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.329200</td>\n",
              "      <td>0.206790</td>\n",
              "      <td>0.454741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.179573</td>\n",
              "      <td>0.423760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.338670</td>\n",
              "      <td>0.581954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.185466</td>\n",
              "      <td>0.430657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.173342</td>\n",
              "      <td>0.416343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.209175</td>\n",
              "      <td>0.457356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.192727</td>\n",
              "      <td>0.439007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.211141</td>\n",
              "      <td>0.459501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.227545</td>\n",
              "      <td>0.477017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.191855</td>\n",
              "      <td>0.438013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.203160</td>\n",
              "      <td>0.450733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.190598</td>\n",
              "      <td>0.436575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.204099</td>\n",
              "      <td>0.451773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 55:42, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.304309</td>\n",
              "      <td>0.551642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.933695</td>\n",
              "      <td>0.966279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.540593</td>\n",
              "      <td>0.735250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.802340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.487913</td>\n",
              "      <td>0.698508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.569145</td>\n",
              "      <td>0.754417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.304006</td>\n",
              "      <td>0.551368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.566451</td>\n",
              "      <td>0.752629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.482761</td>\n",
              "      <td>0.694810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.442661</td>\n",
              "      <td>0.665328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.658933</td>\n",
              "      <td>0.811747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.348753</td>\n",
              "      <td>0.590553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.584243</td>\n",
              "      <td>0.764358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.652080</td>\n",
              "      <td>0.807515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.485402</td>\n",
              "      <td>0.696708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.655547</td>\n",
              "      <td>0.809658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.544434</td>\n",
              "      <td>0.737858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.510356</td>\n",
              "      <td>0.714392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.451266</td>\n",
              "      <td>0.671764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.505392</td>\n",
              "      <td>0.710909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.493279</td>\n",
              "      <td>0.702338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.551924</td>\n",
              "      <td>0.742916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.524561</td>\n",
              "      <td>0.724266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.480716</td>\n",
              "      <td>0.693337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.023700</td>\n",
              "      <td>0.510491</td>\n",
              "      <td>0.714487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 52:28, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.488481</td>\n",
              "      <td>0.698914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.310953</td>\n",
              "      <td>0.557632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.416251</td>\n",
              "      <td>0.645175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.378609</td>\n",
              "      <td>0.615312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.312670</td>\n",
              "      <td>0.559169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.258627</td>\n",
              "      <td>0.508553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.316329</td>\n",
              "      <td>0.562431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.399192</td>\n",
              "      <td>0.631816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.307565</td>\n",
              "      <td>0.554586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>0.289664</td>\n",
              "      <td>0.538205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>0.296143</td>\n",
              "      <td>0.544191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>0.285165</td>\n",
              "      <td>0.534009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>0.265928</td>\n",
              "      <td>0.515682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.550483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.288229</td>\n",
              "      <td>0.536870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.282182</td>\n",
              "      <td>0.531208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.302191</td>\n",
              "      <td>0.549719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.295705</td>\n",
              "      <td>0.543788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.293173</td>\n",
              "      <td>0.541454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.043600</td>\n",
              "      <td>0.302838</td>\n",
              "      <td>0.550307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.043600</td>\n",
              "      <td>0.294230</td>\n",
              "      <td>0.542430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 55:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.614447</td>\n",
              "      <td>0.783866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.682308</td>\n",
              "      <td>0.826019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.175156</td>\n",
              "      <td>1.084046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.977343</td>\n",
              "      <td>0.988607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>0.805650</td>\n",
              "      <td>0.897580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>0.573548</td>\n",
              "      <td>0.757329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>1.073538</td>\n",
              "      <td>1.036117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>0.664057</td>\n",
              "      <td>0.814897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>0.815240</td>\n",
              "      <td>0.902907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.838401</td>\n",
              "      <td>0.915642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.753450</td>\n",
              "      <td>0.868015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.763806</td>\n",
              "      <td>0.873960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.630059</td>\n",
              "      <td>0.793763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.694216</td>\n",
              "      <td>0.833196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.925815</td>\n",
              "      <td>0.962193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.842595</td>\n",
              "      <td>0.917930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.847387</td>\n",
              "      <td>0.920536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.853845</td>\n",
              "      <td>0.924037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.739351</td>\n",
              "      <td>0.859855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.044900</td>\n",
              "      <td>0.807073</td>\n",
              "      <td>0.898372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.044900</td>\n",
              "      <td>0.846660</td>\n",
              "      <td>0.920141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 55:03, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.450144</td>\n",
              "      <td>0.670928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.436635</td>\n",
              "      <td>0.660784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.485680</td>\n",
              "      <td>0.696908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.374336</td>\n",
              "      <td>0.611830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.496500</td>\n",
              "      <td>0.370029</td>\n",
              "      <td>0.608300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.496500</td>\n",
              "      <td>0.258111</td>\n",
              "      <td>0.508046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.496500</td>\n",
              "      <td>0.298619</td>\n",
              "      <td>0.546460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.496500</td>\n",
              "      <td>0.268494</td>\n",
              "      <td>0.518164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.496500</td>\n",
              "      <td>0.316173</td>\n",
              "      <td>0.562292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.308482</td>\n",
              "      <td>0.555411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.253829</td>\n",
              "      <td>0.503814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.309012</td>\n",
              "      <td>0.555889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.343617</td>\n",
              "      <td>0.586189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.261381</td>\n",
              "      <td>0.511254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.298539</td>\n",
              "      <td>0.546387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.282512</td>\n",
              "      <td>0.531518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.261156</td>\n",
              "      <td>0.511034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.269709</td>\n",
              "      <td>0.519335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.297272</td>\n",
              "      <td>0.545227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.290244</td>\n",
              "      <td>0.538743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.280212</td>\n",
              "      <td>0.529351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2270' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2270/2525 50:00 < 05:37, 0.76 it/s, Epoch 4.49/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.830321</td>\n",
              "      <td>0.911220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.506558</td>\n",
              "      <td>0.711729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.650758</td>\n",
              "      <td>0.806696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.468338</td>\n",
              "      <td>0.684352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.412543</td>\n",
              "      <td>0.642295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.708334</td>\n",
              "      <td>0.841626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.548637</td>\n",
              "      <td>0.740700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.454153</td>\n",
              "      <td>0.673909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.450678</td>\n",
              "      <td>0.671325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.438390</td>\n",
              "      <td>0.662110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.583663</td>\n",
              "      <td>0.763979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.460169</td>\n",
              "      <td>0.678357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.442694</td>\n",
              "      <td>0.665353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.533905</td>\n",
              "      <td>0.730688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.508502</td>\n",
              "      <td>0.713093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.428344</td>\n",
              "      <td>0.654480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.425315</td>\n",
              "      <td>0.652162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.469822</td>\n",
              "      <td>0.685436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.434145</td>\n",
              "      <td>0.658897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.452166</td>\n",
              "      <td>0.672433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.457477</td>\n",
              "      <td>0.676370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.458854</td>\n",
              "      <td>0.677387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 56:06, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.830321</td>\n",
              "      <td>0.911220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.506558</td>\n",
              "      <td>0.711729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.650758</td>\n",
              "      <td>0.806696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.468338</td>\n",
              "      <td>0.684352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.412543</td>\n",
              "      <td>0.642295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.708334</td>\n",
              "      <td>0.841626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.548637</td>\n",
              "      <td>0.740700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.454153</td>\n",
              "      <td>0.673909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>0.450678</td>\n",
              "      <td>0.671325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.438390</td>\n",
              "      <td>0.662110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.583663</td>\n",
              "      <td>0.763979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.460169</td>\n",
              "      <td>0.678357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.442694</td>\n",
              "      <td>0.665353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.533905</td>\n",
              "      <td>0.730688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.508502</td>\n",
              "      <td>0.713093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.428344</td>\n",
              "      <td>0.654480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.425315</td>\n",
              "      <td>0.652162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.469822</td>\n",
              "      <td>0.685436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.434145</td>\n",
              "      <td>0.658897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.452166</td>\n",
              "      <td>0.672433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.457477</td>\n",
              "      <td>0.676370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.458854</td>\n",
              "      <td>0.677387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.440941</td>\n",
              "      <td>0.664034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.069400</td>\n",
              "      <td>0.439294</td>\n",
              "      <td>0.662792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>0.446367</td>\n",
              "      <td>0.668107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!mkdir content wording\n",
        "for target in [\"content\", \"wording\"]:\n",
        "    train_by_fold(\n",
        "        train,\n",
        "        model_name=CFG.model_name,\n",
        "        save_each_model=True,\n",
        "        target=target,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "        num_train_epochs=CFG.num_train_epochs,\n",
        "        n_splits=CFG.n_splits,\n",
        "        batch_size=CFG.batch_size,\n",
        "        save_steps=CFG.save_steps,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-AH51-tVvXUm"
      },
      "outputs": [],
      "source": [
        "# !cp -r . /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QSQIR9klJ-bU"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  import json\n",
        "  from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "  def dataset_upload():\n",
        "      global USERID, EX_NO, UPLOAD_DIR\n",
        "      id = f'{USERID}/{EX_NO}'\n",
        "      dataset_metadata = {}\n",
        "      dataset_metadata['id'] = id\n",
        "      dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
        "      dataset_metadata['title'] = f'{TITLE}'\n",
        "      with open(UPLOAD_DIR + 'dataset-metadata.json', 'w') as f:\n",
        "          json.dump(dataset_metadata, f, indent=4)\n",
        "      api = KaggleApi()\n",
        "      api.authenticate()\n",
        "      # データセットがない場合\n",
        "      if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
        "          api.dataset_create_new(folder=UPLOAD_DIR,\n",
        "                                convert_to_csv=False,\n",
        "                                dir_mode='skip'\n",
        "                                #dir_mode='zip'\n",
        "                                )\n",
        "      # データセットがある場合\n",
        "      else:\n",
        "          api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "                                    version_notes='update',\n",
        "                                    convert_to_csv=False,\n",
        "                                    delete_old_versions=True,\n",
        "                                    dir_mode='skip'\n",
        "                                    #dir_mode='zip'\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAY_Cyy2KEtP",
        "outputId": "2a37f995-04fa-40d4-bbec-1fdc0d5a8e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/another-bert/ (stored 0%)\n",
            "  adding: content/another-bert/fold_0/ (stored 0%)\n",
            "  adding: content/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_0/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_1/ (stored 0%)\n",
            "  adding: content/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_1/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_2/ (stored 0%)\n",
            "  adding: content/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_2/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_3/ (stored 0%)\n",
            "  adding: content/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_3/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/ (stored 0%)\n",
            "  adding: wording/another-bert/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_0/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_0/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_1/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_1/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_2/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_2/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_3/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_3/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: pickled.pkl (deflated 72%)\n",
            "CPU times: user 4.38 s, sys: 729 ms, total: 5.11 s\n",
            "Wall time: 24min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl\n",
        "  # !zip -r ./tmp/output  pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRAl0v_YKGu4",
        "outputId": "2f021095-835b-4fe9-d4aa-7054e171471e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting upload for file output.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.2G/10.2G [07:37<00:00, 24.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: output.zip (10GB)\n",
            "CPU times: user 14.6 s, sys: 5.48 s, total: 20.1 s\n",
            "Wall time: 7min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'commitlit-deberta-v3-large-misspel2'\n",
        "  EX_NO = 'commitlit-deberta-v3-large-misspel2'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE56wqWxtltT"
      },
      "outputs": [],
      "source": [
        "# !cp -r ./tmp /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hES5LiE3KNM6"
      },
      "source": [
        "## terminate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXEs3uuDKMG-"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64N212Z7MdTD"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    train = validate(\n",
        "        train,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )\n",
        "\n",
        "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
        "    print(f\"cv {target} rmse: {rmse}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3d_usthVu6c"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    test = predict(\n",
        "        test,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e991A_my4RXY"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWdD32Q8nws"
      },
      "source": [
        "## upload dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzr6yQHa8nBA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRl6J7Y28ySx"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   !mkdir tmp\n",
        "#   !zip -r ./tmp/output content wording pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWzbYTkq86KK"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   TITLE = 'devert-v3-trained'\n",
        "#   EX_NO = 'commitlit-2023'  # 実験番号などを入れる、folderのpathにする\n",
        "#   USERID = 'aruaru0'\n",
        "#   UPLOAD_DIR = './tmp/'\n",
        "#   dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y04vF_2m4RXY"
      },
      "source": [
        "## LGBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NFgHw004RXY"
      },
      "outputs": [],
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\"\n",
        "               ] + targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8X4hieY4RXY"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "            'boosting_type': 'gbdt',\n",
        "            'random_state': 42,\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'learning_rate': 0.048,\n",
        "            'max_depth': 3,\n",
        "            'lambda_l1': 0.0,\n",
        "            'lambda_l2': 0.011\n",
        "        }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zGTNAJKtVEf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lgbm.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4by6kkuhOx"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl lgbm.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9XwAvJnukQL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'roberta-base-trained'\n",
        "  EX_NO = 'roberta-base-trained'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulmFlbGJ4RXY"
      },
      "source": [
        "## CV Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTj7OaLm4RXY"
      },
      "outputs": [],
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlVSzuh64RXY"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9NjgA4Z4RXY"
      },
      "outputs": [],
      "source": [
        "drop_columns = [\n",
        "                #\"fold\",\n",
        "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\n",
        "                \"input\"\n",
        "               ] + [\n",
        "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ] + [\n",
        "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahmlT0hs4RXY"
      },
      "outputs": [],
      "source": [
        "pred_dict = {}\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "    preds = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = test.drop(columns=drop_columns)\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "        preds.append(pred)\n",
        "\n",
        "    pred_dict[target] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Y5dzYt4RXY"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "    preds = pred_dict[target]\n",
        "    for i, pred in enumerate(preds):\n",
        "        test[f\"{target}_pred_{i}\"] = pred\n",
        "\n",
        "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqg9H2uB4RXZ"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58Z_kETy4RXZ"
      },
      "source": [
        "## Create Submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS92zy2v4RXZ"
      },
      "outputs": [],
      "source": [
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIOwTOkaHg7m"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tiflhys4RXZ"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2sQz_YD4RXZ"
      },
      "source": [
        "## Summary\n",
        "\n",
        "CV result is like this.\n",
        "\n",
        "| | content rmse |wording rmse | mcrmse | LB| |\n",
        "| -- | -- | -- | -- | -- | -- |\n",
        "|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n",
        "| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n",
        "| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n",
        "| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n",
        "| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n",
        "\n",
        "The CV values improved slightly, and the LB value is improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8HNdBZX4RXZ"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR64NiYA4RXZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx3MwlI24RXZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "357f0fac4f5f429eb825e59dc607af19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c740bd8269aa4b34a83e0d5d1c7a4877",
              "IPY_MODEL_2f9da7ec302248ae8b89900c6b4fc3be",
              "IPY_MODEL_7712322fea9440de8ab21e078e3129f8"
            ],
            "layout": "IPY_MODEL_d82960fab7a348ac8e8240f7726cc8d4"
          }
        },
        "c740bd8269aa4b34a83e0d5d1c7a4877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7870491a91404534a57e8a14efb0d2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_81620c8c3d7e462592d3e0603f4e1135",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "2f9da7ec302248ae8b89900c6b4fc3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b9175341bee4aaba32e42d8ac778e64",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7a21ac5c4eb4fc8913987fd7c7e9baf",
            "value": 52
          }
        },
        "7712322fea9440de8ab21e078e3129f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192544ae69824dcda0b5bfe3d161687b",
            "placeholder": "​",
            "style": "IPY_MODEL_3ed97600141d4818b4fc6e474a336d43",
            "value": " 52.0/52.0 [00:00&lt;00:00, 3.92kB/s]"
          }
        },
        "d82960fab7a348ac8e8240f7726cc8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7870491a91404534a57e8a14efb0d2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81620c8c3d7e462592d3e0603f4e1135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b9175341bee4aaba32e42d8ac778e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a21ac5c4eb4fc8913987fd7c7e9baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "192544ae69824dcda0b5bfe3d161687b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed97600141d4818b4fc6e474a336d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3661842a2de42d2b559e0aed6009032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4bfe2dc9249482b932deff8dbdc78a4",
              "IPY_MODEL_7e98de290a7d4bdc9856ead361050e9f",
              "IPY_MODEL_63b6381122a64466b8de6312ad9111c4"
            ],
            "layout": "IPY_MODEL_dae6ae07a4ba4125a8c060eb9704df32"
          }
        },
        "c4bfe2dc9249482b932deff8dbdc78a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a94e1414e34ac7b3206eea841db0d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ba3d9c1859eb43ccb1acd6e1bb47e8f5",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7e98de290a7d4bdc9856ead361050e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33aedebd0fd45bd8aba9e9db400baca",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d879293fa270435cbef2223a596d34d1",
            "value": 580
          }
        },
        "63b6381122a64466b8de6312ad9111c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73c5dfd500c4defacbd74c8ac86855f",
            "placeholder": "​",
            "style": "IPY_MODEL_958a72c0d3fa4a8abac85762aad96779",
            "value": " 580/580 [00:00&lt;00:00, 58.2kB/s]"
          }
        },
        "dae6ae07a4ba4125a8c060eb9704df32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a94e1414e34ac7b3206eea841db0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3d9c1859eb43ccb1acd6e1bb47e8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f33aedebd0fd45bd8aba9e9db400baca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d879293fa270435cbef2223a596d34d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d73c5dfd500c4defacbd74c8ac86855f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958a72c0d3fa4a8abac85762aad96779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a3857f4a9546babbe476d9a0e59301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5835b46278a441ba03659fc29c85d43",
              "IPY_MODEL_6be3769bd0f54718aa6d4438b9792962",
              "IPY_MODEL_5a9ec6f594084459a3551ebbf945c627"
            ],
            "layout": "IPY_MODEL_2a031e4f52af408780c7bcf1a80dd04f"
          }
        },
        "c5835b46278a441ba03659fc29c85d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a214e7fb714b4a94ed2500ed037392",
            "placeholder": "​",
            "style": "IPY_MODEL_ee96d111751a4d1d953a9f10b3b742df",
            "value": "Downloading spm.model: 100%"
          }
        },
        "6be3769bd0f54718aa6d4438b9792962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51062018306e49028985d346a0a13cca",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9a397403fc74322bc334bd6b60d9c29",
            "value": 2464616
          }
        },
        "5a9ec6f594084459a3551ebbf945c627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a377c9482641d08bd13ddbd144122b",
            "placeholder": "​",
            "style": "IPY_MODEL_c73cf5a130aa45e5bb33b8b06312b6bd",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 52.8MB/s]"
          }
        },
        "2a031e4f52af408780c7bcf1a80dd04f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a214e7fb714b4a94ed2500ed037392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee96d111751a4d1d953a9f10b3b742df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51062018306e49028985d346a0a13cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a397403fc74322bc334bd6b60d9c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09a377c9482641d08bd13ddbd144122b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73cf5a130aa45e5bb33b8b06312b6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "458c54163df44c4386f2b30e2db12288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71573d052959407e8371cc7d1c4a6100",
              "IPY_MODEL_c92534e1fc894226981376968ef66bf7",
              "IPY_MODEL_1e12b878dc7c4768adaebd382bf9d796"
            ],
            "layout": "IPY_MODEL_f1c9cb4f422f499481b8d27515ce0932"
          }
        },
        "71573d052959407e8371cc7d1c4a6100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a60bfc2f5d4b80b38849ac6fb15e26",
            "placeholder": "​",
            "style": "IPY_MODEL_cc6a70f34a40442f9ba0113e02ecc59c",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "c92534e1fc894226981376968ef66bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b9965268b54a43a2d71bade997a88f",
            "max": 873673253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3b6482054ab4c67bdc399f2a6bd773a",
            "value": 873673253
          }
        },
        "1e12b878dc7c4768adaebd382bf9d796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbcbf045dc154a89a0980c4e648e8f28",
            "placeholder": "​",
            "style": "IPY_MODEL_d07065c2284a467c9460a30300f706db",
            "value": " 874M/874M [00:02&lt;00:00, 408MB/s]"
          }
        },
        "f1c9cb4f422f499481b8d27515ce0932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a60bfc2f5d4b80b38849ac6fb15e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6a70f34a40442f9ba0113e02ecc59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b9965268b54a43a2d71bade997a88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b6482054ab4c67bdc399f2a6bd773a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbcbf045dc154a89a0980c4e648e8f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07065c2284a467c9460a30300f706db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}