{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/CommonLit-Evaluate-Student-Summaries/blob/main/misspellings2_debertav3L_lgbm_autocorrect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FkXnqfL4Vd0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_917tB4eGO",
        "outputId": "b62ea988-2682-4599-b9e1-a1e7d2bf0348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hSZqxM34hSK"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  !mkdir -p /root/.kaggle\n",
        "  !cp /content/drive/MyDrive/Kaggle/kaggle.json  /root/.kaggle/\n",
        "  !chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgkYiHO4qhy",
        "outputId": "c3f13d37-555d-46fa-ac37-f02be13384fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install kaggle\n",
        "  !apt install unzip\n",
        "  !mkdir input output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5vNe0z44tmh",
        "outputId": "452dcc92-e179-4bee-87e9-eeb7092e8955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            " 95% 1.00M/1.05M [00:00<00:00, 1.99MB/s]\n",
            "100% 1.05M/1.05M [00:00<00:00, 2.08MB/s]\n",
            "Archive:  commonlit-evaluate-student-summaries.zip\n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_train.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/sample_submission.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_train.csv  \n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !kaggle competitions download -c commonlit-evaluate-student-summaries\n",
        "  !unzip -o commonlit-evaluate-student-summaries.zip -d input/commonlit-evaluate-student-summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aCDfcTM6l1n",
        "outputId": "86e75c9e-fb62-497e-c30d-44b0d7e6b33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting autocorrect==2.6\n",
            "  Downloading autocorrect-2.6.0.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.6/622.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.0-py3-none-any.whl size=622231 sha256=a0c68023d17347ba27048ff60ab9771386df574b9296fb9d68ec00ea50508a8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/66/c6/7470703fc0cd7739a9bbfd7bf8d2b42b2df4eeeca5be85ad7a\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.0\n",
            "Collecting pyspellchecker==0.7.2\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install transformers\n",
        "  !pip install datasets\n",
        "  !pip install sentencepiece\n",
        "  !pip install autocorrect==2.6\n",
        "  !pip install pyspellchecker==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owJ9XYkWC33k",
        "outputId": "062faabc-e6f9-401a-f3d2-4c24f79a7f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-d7p8vjc9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-d7p8vjc9\n",
            "  Resolved https://github.com/huggingface/accelerate to commit cbb0b82fa2590f9b02e651724c51dd6701158100\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.24.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.24.0.dev0-py3-none-any.whl size=258569 sha256=5f5ac556cd19bf9b35d6215780d9b98ad5d198cfd3d642ed4cfba04143decb18\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i9b1hisa/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.0.dev0\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_dxr0ku-Vw8"
      },
      "source": [
        "# ここでランタイムの再起動が必要！！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtdyP9QL7hFs",
        "outputId": "583960f9-6617-4627-e7b4-cf312d4174d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/output\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True\n",
        "\n",
        "if is_colab:\n",
        "  %cd output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdROKpaD7DWX",
        "outputId": "98cc9c6d-7e40-4d32-f72e-8fd54f13fb73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "  model_name = \"microsoft/deberta-v3-large\"\n",
        "  # model_name = \"roberta-base\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  hidden_dropout_prob=0.007\n",
        "  attention_probs_dropout_prob=0.007\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "  model_dir = \"../input/another-bert\"\n",
        "  model.save_pretrained(model_dir)\n",
        "  tokenizer.save_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BFTn4SLsclH",
        "outputId": "c9feb1b8-95f4-40f8-8243-a2553e348875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deberta.embeddings.word_embeddings.weight True\n",
            "deberta.embeddings.LayerNorm.weight True\n",
            "deberta.embeddings.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.0.attention.output.dense.weight True\n",
            "deberta.encoder.layer.0.attention.output.dense.bias True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.intermediate.dense.weight True\n",
            "deberta.encoder.layer.0.intermediate.dense.bias True\n",
            "deberta.encoder.layer.0.output.dense.weight True\n",
            "deberta.encoder.layer.0.output.dense.bias True\n",
            "deberta.encoder.layer.0.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.1.attention.output.dense.weight True\n",
            "deberta.encoder.layer.1.attention.output.dense.bias True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.intermediate.dense.weight True\n",
            "deberta.encoder.layer.1.intermediate.dense.bias True\n",
            "deberta.encoder.layer.1.output.dense.weight True\n",
            "deberta.encoder.layer.1.output.dense.bias True\n",
            "deberta.encoder.layer.1.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.2.attention.output.dense.weight True\n",
            "deberta.encoder.layer.2.attention.output.dense.bias True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.intermediate.dense.weight True\n",
            "deberta.encoder.layer.2.intermediate.dense.bias True\n",
            "deberta.encoder.layer.2.output.dense.weight True\n",
            "deberta.encoder.layer.2.output.dense.bias True\n",
            "deberta.encoder.layer.2.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.3.attention.output.dense.weight True\n",
            "deberta.encoder.layer.3.attention.output.dense.bias True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.intermediate.dense.weight True\n",
            "deberta.encoder.layer.3.intermediate.dense.bias True\n",
            "deberta.encoder.layer.3.output.dense.weight True\n",
            "deberta.encoder.layer.3.output.dense.bias True\n",
            "deberta.encoder.layer.3.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.4.attention.output.dense.weight True\n",
            "deberta.encoder.layer.4.attention.output.dense.bias True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.intermediate.dense.weight True\n",
            "deberta.encoder.layer.4.intermediate.dense.bias True\n",
            "deberta.encoder.layer.4.output.dense.weight True\n",
            "deberta.encoder.layer.4.output.dense.bias True\n",
            "deberta.encoder.layer.4.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.5.attention.output.dense.weight True\n",
            "deberta.encoder.layer.5.attention.output.dense.bias True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.intermediate.dense.weight True\n",
            "deberta.encoder.layer.5.intermediate.dense.bias True\n",
            "deberta.encoder.layer.5.output.dense.weight True\n",
            "deberta.encoder.layer.5.output.dense.bias True\n",
            "deberta.encoder.layer.5.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.6.attention.output.dense.weight True\n",
            "deberta.encoder.layer.6.attention.output.dense.bias True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.intermediate.dense.weight True\n",
            "deberta.encoder.layer.6.intermediate.dense.bias True\n",
            "deberta.encoder.layer.6.output.dense.weight True\n",
            "deberta.encoder.layer.6.output.dense.bias True\n",
            "deberta.encoder.layer.6.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.7.attention.output.dense.weight True\n",
            "deberta.encoder.layer.7.attention.output.dense.bias True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.intermediate.dense.weight True\n",
            "deberta.encoder.layer.7.intermediate.dense.bias True\n",
            "deberta.encoder.layer.7.output.dense.weight True\n",
            "deberta.encoder.layer.7.output.dense.bias True\n",
            "deberta.encoder.layer.7.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.8.attention.output.dense.weight True\n",
            "deberta.encoder.layer.8.attention.output.dense.bias True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.intermediate.dense.weight True\n",
            "deberta.encoder.layer.8.intermediate.dense.bias True\n",
            "deberta.encoder.layer.8.output.dense.weight True\n",
            "deberta.encoder.layer.8.output.dense.bias True\n",
            "deberta.encoder.layer.8.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.9.attention.output.dense.weight True\n",
            "deberta.encoder.layer.9.attention.output.dense.bias True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.intermediate.dense.weight True\n",
            "deberta.encoder.layer.9.intermediate.dense.bias True\n",
            "deberta.encoder.layer.9.output.dense.weight True\n",
            "deberta.encoder.layer.9.output.dense.bias True\n",
            "deberta.encoder.layer.9.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.10.attention.output.dense.weight True\n",
            "deberta.encoder.layer.10.attention.output.dense.bias True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.intermediate.dense.weight True\n",
            "deberta.encoder.layer.10.intermediate.dense.bias True\n",
            "deberta.encoder.layer.10.output.dense.weight True\n",
            "deberta.encoder.layer.10.output.dense.bias True\n",
            "deberta.encoder.layer.10.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.11.attention.output.dense.weight True\n",
            "deberta.encoder.layer.11.attention.output.dense.bias True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.intermediate.dense.weight True\n",
            "deberta.encoder.layer.11.intermediate.dense.bias True\n",
            "deberta.encoder.layer.11.output.dense.weight True\n",
            "deberta.encoder.layer.11.output.dense.bias True\n",
            "deberta.encoder.layer.11.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.12.attention.output.dense.weight True\n",
            "deberta.encoder.layer.12.attention.output.dense.bias True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.intermediate.dense.weight True\n",
            "deberta.encoder.layer.12.intermediate.dense.bias True\n",
            "deberta.encoder.layer.12.output.dense.weight True\n",
            "deberta.encoder.layer.12.output.dense.bias True\n",
            "deberta.encoder.layer.12.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.13.attention.output.dense.weight True\n",
            "deberta.encoder.layer.13.attention.output.dense.bias True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.intermediate.dense.weight True\n",
            "deberta.encoder.layer.13.intermediate.dense.bias True\n",
            "deberta.encoder.layer.13.output.dense.weight True\n",
            "deberta.encoder.layer.13.output.dense.bias True\n",
            "deberta.encoder.layer.13.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.14.attention.output.dense.weight True\n",
            "deberta.encoder.layer.14.attention.output.dense.bias True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.intermediate.dense.weight True\n",
            "deberta.encoder.layer.14.intermediate.dense.bias True\n",
            "deberta.encoder.layer.14.output.dense.weight True\n",
            "deberta.encoder.layer.14.output.dense.bias True\n",
            "deberta.encoder.layer.14.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.15.attention.output.dense.weight True\n",
            "deberta.encoder.layer.15.attention.output.dense.bias True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.intermediate.dense.weight True\n",
            "deberta.encoder.layer.15.intermediate.dense.bias True\n",
            "deberta.encoder.layer.15.output.dense.weight True\n",
            "deberta.encoder.layer.15.output.dense.bias True\n",
            "deberta.encoder.layer.15.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.16.attention.output.dense.weight True\n",
            "deberta.encoder.layer.16.attention.output.dense.bias True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.intermediate.dense.weight True\n",
            "deberta.encoder.layer.16.intermediate.dense.bias True\n",
            "deberta.encoder.layer.16.output.dense.weight True\n",
            "deberta.encoder.layer.16.output.dense.bias True\n",
            "deberta.encoder.layer.16.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.17.attention.output.dense.weight True\n",
            "deberta.encoder.layer.17.attention.output.dense.bias True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.intermediate.dense.weight True\n",
            "deberta.encoder.layer.17.intermediate.dense.bias True\n",
            "deberta.encoder.layer.17.output.dense.weight True\n",
            "deberta.encoder.layer.17.output.dense.bias True\n",
            "deberta.encoder.layer.17.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.18.attention.output.dense.weight True\n",
            "deberta.encoder.layer.18.attention.output.dense.bias True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.intermediate.dense.weight True\n",
            "deberta.encoder.layer.18.intermediate.dense.bias True\n",
            "deberta.encoder.layer.18.output.dense.weight True\n",
            "deberta.encoder.layer.18.output.dense.bias True\n",
            "deberta.encoder.layer.18.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.19.attention.output.dense.weight True\n",
            "deberta.encoder.layer.19.attention.output.dense.bias True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.intermediate.dense.weight True\n",
            "deberta.encoder.layer.19.intermediate.dense.bias True\n",
            "deberta.encoder.layer.19.output.dense.weight True\n",
            "deberta.encoder.layer.19.output.dense.bias True\n",
            "deberta.encoder.layer.19.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.20.attention.output.dense.weight True\n",
            "deberta.encoder.layer.20.attention.output.dense.bias True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.intermediate.dense.weight True\n",
            "deberta.encoder.layer.20.intermediate.dense.bias True\n",
            "deberta.encoder.layer.20.output.dense.weight True\n",
            "deberta.encoder.layer.20.output.dense.bias True\n",
            "deberta.encoder.layer.20.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.21.attention.output.dense.weight True\n",
            "deberta.encoder.layer.21.attention.output.dense.bias True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.intermediate.dense.weight True\n",
            "deberta.encoder.layer.21.intermediate.dense.bias True\n",
            "deberta.encoder.layer.21.output.dense.weight True\n",
            "deberta.encoder.layer.21.output.dense.bias True\n",
            "deberta.encoder.layer.21.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.22.attention.output.dense.weight True\n",
            "deberta.encoder.layer.22.attention.output.dense.bias True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.intermediate.dense.weight True\n",
            "deberta.encoder.layer.22.intermediate.dense.bias True\n",
            "deberta.encoder.layer.22.output.dense.weight True\n",
            "deberta.encoder.layer.22.output.dense.bias True\n",
            "deberta.encoder.layer.22.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.23.attention.output.dense.weight True\n",
            "deberta.encoder.layer.23.attention.output.dense.bias True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.intermediate.dense.weight True\n",
            "deberta.encoder.layer.23.intermediate.dense.bias True\n",
            "deberta.encoder.layer.23.output.dense.weight True\n",
            "deberta.encoder.layer.23.output.dense.bias True\n",
            "deberta.encoder.layer.23.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.output.LayerNorm.bias True\n",
            "deberta.encoder.rel_embeddings.weight True\n",
            "deberta.encoder.LayerNorm.weight True\n",
            "deberta.encoder.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        " # You can confirm which layers have been frozen and see the whole layer struct of the model\n",
        " for n, p in model.named_parameters():\n",
        "    print(n, p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edsSr0fIs2y2"
      },
      "outputs": [],
      "source": [
        "def top_half_layer_freeze(model):\n",
        "    for n,p in model.named_parameters():\n",
        "        if f\".embeddings\" in n:\n",
        "            p.requires_grad = False\n",
        "\n",
        "    for i in range(0,6,1):\n",
        "        for n,p in model.named_parameters():\n",
        "            if f'encoder.layer.{i}.' in n:\n",
        "                p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OcffOfUs4OC"
      },
      "outputs": [],
      "source": [
        "top_half_layer_freeze(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMpRe4l5AO_P",
        "outputId": "933a6021-61d4-49fc-971e-7ced4e9f4bfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnE6iEp4RXS"
      },
      "source": [
        "# Notes\n",
        "This is a slightly tuned version of @nogawanogawa 's work and I have also converted his messages to english here you can find his notebook here https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-spell-autocorrect please give him kudos for sharing his efforts\n",
        "\n",
        "### Things I would expect there to be a number of things that will allow this model to preform better outside of just strategy and more data. I would imagine there are a few more tuning parameters that could help this model go a long way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this notebook a combonation of Deberta and LGBM is used, pyspellchecker is also used in order to correct some of the spelling mistakes that are discussed in the discussions tab\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "[my previous notebook](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering)\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "\n",
        "The primary goal of this notebook is to enhance the overall score by honing in on the issue of \"misspellings.\"\n",
        "\n",
        "## Main Concept\n",
        "\n",
        "The Transformers model I'm currently utilizing, Deberta, is pretrained on \"correct sentences.\" However, if I were to train and input it with sentences containing misspellings, Deberta's ability to understand meaning might be compromised.\n",
        "\n",
        "From a human evaluator's perspective, detecting misspellings would prompt deductions in scores. After discreetly rectifying the misspelled words, I'd proceed to evaluate other textual facets. If we assume the scoring process aligns with this approach, it's conceivable that tallying and **correcting** misspellings before feeding text into Deberta could enable the model to aptly capture features beyond just misspellings.\n",
        "\n",
        "In this notebook, I will embark on the journey of auto-correcting misspelled words before inputting them into Deberta. The aim is to evaluate the model's performance by distinctly isolating misspellings from other aspects.\n",
        "\n",
        "### Feature Engineering\n",
        "\n",
        "I intend to largely retain the same features as before:\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - Count\n",
        "  - Ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - Spelling: pyspellchecker\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "I plan to construct a model with the architecture depicted in the following diagram. For the input to Deberta (`text`), I will pre-process by correcting any misspellings. In other aspects of feature engineering, I will utilize the `text` as is.\n",
        "\n",
        "### References\n",
        "\n",
        "- https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941\n",
        "\n",
        "### My previous notebooks\n",
        "\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-with-llama2-example\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3e8TQJd4RXU"
      },
      "outputs": [],
      "source": [
        "if not is_colab :\n",
        "  !pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
        "  !pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkGQJ0tu4RXV"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset,load_dataset, load_from_disk\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric, disable_progress_bar\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "from autocorrect import Speller\n",
        "from spellchecker import SpellChecker\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTSJWXAjvRa",
        "outputId": "5253a228-0316-4fba-c896-ddc38782c7c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu= 8\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "cpu_num = multiprocessing.cpu_count()\n",
        "print(\"cpu=\", cpu_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwl4vqgbjyBh"
      },
      "outputs": [],
      "source": [
        "seed_base = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-pPPJ3a4RXV"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=seed_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfBN_xxH4RXW"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name=\"another-bert\"\n",
        "    learning_rate=1.5e-5\n",
        "    weight_decay=0.02\n",
        "    hidden_dropout_prob=0.007\n",
        "    attention_probs_dropout_prob=0.007\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=3\n",
        "\n",
        "    random_seed=seed_base\n",
        "    save_steps=100\n",
        "    max_length=512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzSk2kRA4RXW"
      },
      "source": [
        "## Dataload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3nYzKoi4RXW"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"../input/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2huhIeJ4RXW"
      },
      "source": [
        "## Preprocess\n",
        "\n",
        "[Using features]\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - count\n",
        "  - ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - spelling: pyspellchecker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7F-j8-I_e18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hESbPb6N4RXW"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                ) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.twd = TreebankWordDetokenizer()\n",
        "        self.STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
        "        self.speller = Speller(lang='en')\n",
        "        self.spellchecker = SpellChecker()\n",
        "\n",
        "    def word_overlap_count(self, row):\n",
        "        \"\"\" intersection(prompt_text, text) \"\"\"\n",
        "        def check_is_stop_word(word):\n",
        "            return word in self.STOP_WORDS\n",
        "\n",
        "        prompt_words = row['prompt_tokens']\n",
        "        summary_words = row['summary_tokens']\n",
        "        if self.STOP_WORDS:\n",
        "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
        "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
        "        return len(set(prompt_words).intersection(set(summary_words)))\n",
        "\n",
        "    def ngrams(self, token, n):\n",
        "        # Use the zip function to help us generate n-grams\n",
        "        # Concatentate the tokens into ngrams and return\n",
        "        ngrams = zip(*[token[i:] for i in range(n)])\n",
        "        return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
        "        # Tokenize the original text and summary into words\n",
        "        original_tokens = row['prompt_tokens']\n",
        "        summary_tokens = row['summary_tokens']\n",
        "\n",
        "        # Generate n-grams for the original text and summary\n",
        "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
        "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
        "\n",
        "        # Calculate the number of common n-grams\n",
        "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
        "        return len(common_ngrams)\n",
        "\n",
        "    def ner_overlap_count(self, row, mode:str):\n",
        "        model = self.spacy_ner_model\n",
        "        def clean_ners(ner_list):\n",
        "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
        "        prompt = model(row['prompt_text'])\n",
        "        summary = model(row['text'])\n",
        "\n",
        "        if \"spacy\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
        "        elif \"stanza\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
        "        else:\n",
        "            raise Exception(\"Model not supported\")\n",
        "\n",
        "        prompt_ner = clean_ners(prompt_ner)\n",
        "        summary_ner = clean_ners(summary_ner)\n",
        "\n",
        "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
        "\n",
        "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
        "\n",
        "        if mode == \"train\":\n",
        "            return ner_dict\n",
        "        elif mode == \"test\":\n",
        "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
        "\n",
        "\n",
        "    def quotes_count(self, row):\n",
        "        summary = row['text']\n",
        "        text = row['prompt_text']\n",
        "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
        "        if len(quotes_from_summary)>0:\n",
        "            return [quote in text for quote in quotes_from_summary].count(True)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def spelling(self, text):\n",
        "\n",
        "        wordlist=text.split()\n",
        "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
        "\n",
        "        return amount_miss\n",
        "\n",
        "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
        "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
        "        self.spellchecker.word_frequency.load_words(tokens)\n",
        "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
        "\n",
        "    def run(self,\n",
        "            prompts: pd.DataFrame,\n",
        "            summaries:pd.DataFrame,\n",
        "            mode:str\n",
        "        ) -> pd.DataFrame:\n",
        "\n",
        "        # before merge preprocess\n",
        "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        # Add prompt tokens into spelling checker dictionary\n",
        "        prompts[\"prompt_tokens\"].apply(\n",
        "            lambda x: self.add_spelling_dictionary(x)\n",
        "        )\n",
        "\n",
        "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "        # fix misspelling\n",
        "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
        "            lambda x: self.speller(x)\n",
        "        )\n",
        "\n",
        "        # count misspelling\n",
        "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
        "\n",
        "        # merge prompts and summaries\n",
        "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
        "\n",
        "        # after merge preprocess\n",
        "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
        "\n",
        "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
        "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence,args=(2,), axis=1\n",
        "        )\n",
        "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
        "\n",
        "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence, args=(3,), axis=1\n",
        "        )\n",
        "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
        "\n",
        "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
        "\n",
        "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
        "\n",
        "preprocessor = Preprocessor(model_name=CFG.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "CJEL4wDV4RXX",
        "outputId": "e27fda93-a5c5-4a9e-ac7f-12bd365652e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7165/7165 [06:46<00:00, 17.64it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 7865.88it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 9074.89it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4867.45it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4498.04it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 81098.95it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7752.87it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 9903.91it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3920.83it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 4606.59it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3877.33it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3742.41it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7209fe2c-ce2e-498c-b99e-b3c8842fd4cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7209fe2c-ce2e-498c-b99e-b3c8842fd4cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7209fe2c-ce2e-498c-b99e-b3c8842fd4cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7209fe2c-ce2e-498c-b99e-b3c8842fd4cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-faa39d46-4079-4d09-aff7-fe493dce2a5b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-faa39d46-4079-4d09-aff7-fe493dce2a5b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-faa39d46-4079-4d09-aff7-fe493dce2a5b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  \n",
              "0             0  \n",
              "1             0  \n",
              "2             2  \n",
              "3             0  \n",
              "4             4  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
        "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqEJ3DWX4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'wb') as f:\n",
        "    pickle.dump(train, f)\n",
        "    pickle.dump(test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxMtKG9l4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'rb') as f:\n",
        "    train = pickle.load(f)\n",
        "    test = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCo_NEhg6SEb"
      },
      "outputs": [],
      "source": [
        "# train = train[:512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "YavvVjbl4RXX",
        "outputId": "aaa1c5aa-9185-40b2-fe1b-9e8df881c005"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e8bdb9a3-8625-439e-b52b-f7d03517d486\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8bdb9a3-8625-439e-b52b-f7d03517d486')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8bdb9a3-8625-439e-b52b-f7d03517d486 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8bdb9a3-8625-439e-b52b-f7d03517d486');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f02131f9-19e7-4e85-b55f-b9034e3e29b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f02131f9-19e7-4e85-b55f-b9034e3e29b7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f02131f9-19e7-4e85-b55f-b9034e3e29b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  fold  \n",
              "0             0   3.0  \n",
              "1             0   2.0  \n",
              "2             2   1.0  \n",
              "3             0   1.0  \n",
              "4             4   3.0  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ40iLxj4RXX"
      },
      "source": [
        "## Model Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6JS7cYm4RXX"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_BYbqcT4RXX"
      },
      "source": [
        "## Deberta Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne-jnegYEw4C"
      },
      "outputs": [],
      "source": [
        "class ContentScoreRegressor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                model_dir: str,\n",
        "                target: str,\n",
        "                hidden_dropout_prob: float,\n",
        "                attention_probs_dropout_prob: float,\n",
        "                max_length: int,\n",
        "                ):\n",
        "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
        "        self.input_col = \"input\"\n",
        "\n",
        "        self.text_cols = [self.input_col]\n",
        "        self.target = target\n",
        "        self.target_cols = [target]\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.model_dir = model_dir\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.model_config = AutoConfig.from_pretrained(f\"../input/{model_name}\")\n",
        "\n",
        "        self.model_config.update({\n",
        "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
        "            \"num_labels\": 1,\n",
        "            \"problem_type\": \"regression\",\n",
        "        })\n",
        "\n",
        "        seed_everything(seed=42)\n",
        "\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=self.tokenizer\n",
        "        )\n",
        "\n",
        "\n",
        "    def tokenize_function(self, examples: pd.DataFrame):\n",
        "        labels = [examples[self.target]]\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return {\n",
        "            **tokenized,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return tokenized\n",
        "\n",
        "    def train(self,\n",
        "            fold: int,\n",
        "            train_df: pd.DataFrame,\n",
        "            valid_df: pd.DataFrame,\n",
        "            batch_size: int,\n",
        "            learning_rate: float,\n",
        "            weight_decay: float,\n",
        "            num_train_epochs: float,\n",
        "            save_steps: int,\n",
        "        ) -> None:\n",
        "        \"\"\"fine-tuning\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        train_df[self.input_col] = (\n",
        "                    train_df[\"prompt_title\"] + sep\n",
        "                    + train_df[\"prompt_question\"] + sep\n",
        "                    + train_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + train_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        valid_df[self.input_col] = (\n",
        "                    valid_df[\"prompt_title\"] + sep\n",
        "                    + valid_df[\"prompt_question\"] + sep\n",
        "                    + valid_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + valid_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        train_df = train_df[[self.input_col] + self.target_cols]\n",
        "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
        "            f\"../input/{self.model_name}\",\n",
        "            config=self.model_config,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        top_half_layer_freeze(model_content)\n",
        "\n",
        "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
        "\n",
        "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
        "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
        "\n",
        "        # eg. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            load_best_model_at_end=True, # select best model\n",
        "            learning_rate=learning_rate,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=4,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            report_to='none',\n",
        "            greater_is_better=False,\n",
        "            save_strategy=\"steps\",\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=save_steps,\n",
        "            save_steps=save_steps,\n",
        "            metric_for_best_model=\"rmse\",\n",
        "            save_total_limit=1,\n",
        "            fp16=True,\n",
        "            warmup_steps = 100,\n",
        "            gradient_accumulation_steps = 4,\n",
        "            dataloader_num_workers = cpu_num,\n",
        "            )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model_content,\n",
        "            args=training_args,\n",
        "            train_dataset=train_tokenized_datasets,\n",
        "            eval_dataset=val_tokenized_datasets,\n",
        "            tokenizer=self.tokenizer,\n",
        "            compute_metrics=compute_metrics,\n",
        "            data_collator=self.data_collator\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        shutil.rmtree(self.model_dir)\n",
        "\n",
        "        model_content.save_pretrained(self.model_dir)\n",
        "        self.tokenizer.save_pretrained(self.model_dir)\n",
        "\n",
        "\n",
        "    def predict(self,\n",
        "                test_df: pd.DataFrame,\n",
        "                fold: int,\n",
        "               ):\n",
        "        \"\"\"predict content score\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        in_text = (\n",
        "                    test_df[\"prompt_title\"] + sep\n",
        "                    + test_df[\"prompt_question\"] + sep\n",
        "                    + test_df['splling_err_num'].astype(str) + \" misspellings\" + sep\n",
        "                    + test_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "        test_df[self.input_col] = in_text\n",
        "\n",
        "        test_ = test_df[[self.input_col]]\n",
        "\n",
        "        test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n",
        "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
        "        model_content.eval()\n",
        "\n",
        "        # e.g. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = 4,\n",
        "            dataloader_drop_last = False,\n",
        "        )\n",
        "\n",
        "        # init trainer\n",
        "        infer_content = Trainer(\n",
        "                      model = model_content,\n",
        "                      tokenizer=self.tokenizer,\n",
        "                      data_collator=self.data_collator,\n",
        "                      args = test_args)\n",
        "\n",
        "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-yViAlt4RXX"
      },
      "outputs": [],
      "source": [
        "def train_by_fold(\n",
        "        train_df: pd.DataFrame,\n",
        "        model_name: str,\n",
        "        target:str,\n",
        "        save_each_model: bool,\n",
        "        n_splits: int,\n",
        "        batch_size: int,\n",
        "        learning_rate: int,\n",
        "        hidden_dropout_prob: float,\n",
        "        attention_probs_dropout_prob: float,\n",
        "        weight_decay: float,\n",
        "        num_train_epochs: int,\n",
        "        save_steps: int,\n",
        "        max_length:int\n",
        "    ):\n",
        "\n",
        "    # delete old model files\n",
        "    if os.path.exists(model_name):\n",
        "        shutil.rmtree(model_name)\n",
        "\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        train_data = train_df[train_df[\"fold\"] != fold]\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        csr.train(\n",
        "            fold=fold,\n",
        "            train_df=train_data,\n",
        "            valid_df=valid_data,\n",
        "            batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=weight_decay,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            save_steps=save_steps,\n",
        "        )\n",
        "\n",
        "def validate(\n",
        "    train_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict oof data\"\"\"\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=valid_data,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
        "\n",
        "    return train_df\n",
        "\n",
        "def predict(\n",
        "    test_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ):\n",
        "    \"\"\"predict using mean folds\"\"\"\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=test_df,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
        "\n",
        "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
        "\n",
        "    return test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8twHE2C44RXY",
        "outputId": "1fb96265-3b05-417c-9686-bf7fac3831a1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 49:01, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.734023</td>\n",
              "      <td>0.856751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.354980</td>\n",
              "      <td>0.595802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.287896</td>\n",
              "      <td>0.536559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.179117</td>\n",
              "      <td>0.423222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.484891</td>\n",
              "      <td>0.696341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.226890</td>\n",
              "      <td>0.476330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.167417</td>\n",
              "      <td>0.409167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.156959</td>\n",
              "      <td>0.396181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.230772</td>\n",
              "      <td>0.480387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.328803</td>\n",
              "      <td>0.573413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.212878</td>\n",
              "      <td>0.461387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.325516</td>\n",
              "      <td>0.570540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.262096</td>\n",
              "      <td>0.511953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.247238</td>\n",
              "      <td>0.497230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.256810</td>\n",
              "      <td>0.506765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.293935</td>\n",
              "      <td>0.542158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.227217</td>\n",
              "      <td>0.476672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.228231</td>\n",
              "      <td>0.477735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.205723</td>\n",
              "      <td>0.453567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.228380</td>\n",
              "      <td>0.477891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.225515</td>\n",
              "      <td>0.474884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/2145 11:02 < 36:21, 0.75 it/s, Epoch 1.16/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.428921</td>\n",
              "      <td>0.654920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275150</td>\n",
              "      <td>0.524548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.272982</td>\n",
              "      <td>0.522477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.384609</td>\n",
              "      <td>0.620168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='107' max='503' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [107/503 00:10 < 00:39, 10.12 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 51:21, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.428921</td>\n",
              "      <td>0.654920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275150</td>\n",
              "      <td>0.524548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.272982</td>\n",
              "      <td>0.522477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.384609</td>\n",
              "      <td>0.620168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.303700</td>\n",
              "      <td>0.283400</td>\n",
              "      <td>0.532354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.303700</td>\n",
              "      <td>0.336493</td>\n",
              "      <td>0.580080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.303700</td>\n",
              "      <td>0.387358</td>\n",
              "      <td>0.622381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.303700</td>\n",
              "      <td>0.379986</td>\n",
              "      <td>0.616430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.303700</td>\n",
              "      <td>0.284541</td>\n",
              "      <td>0.533424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.285557</td>\n",
              "      <td>0.534375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.244937</td>\n",
              "      <td>0.494911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.246857</td>\n",
              "      <td>0.496847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.247471</td>\n",
              "      <td>0.497465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.243490</td>\n",
              "      <td>0.493447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.248027</td>\n",
              "      <td>0.498023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.261805</td>\n",
              "      <td>0.511669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.287866</td>\n",
              "      <td>0.536531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.257919</td>\n",
              "      <td>0.507858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.231190</td>\n",
              "      <td>0.480822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.249002</td>\n",
              "      <td>0.499001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.248853</td>\n",
              "      <td>0.498851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 50:48, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.289366</td>\n",
              "      <td>0.537928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.232908</td>\n",
              "      <td>0.482606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.356436</td>\n",
              "      <td>0.597022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.325353</td>\n",
              "      <td>0.570397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.335994</td>\n",
              "      <td>0.579650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.262564</td>\n",
              "      <td>0.512410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.358739</td>\n",
              "      <td>0.598948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.221063</td>\n",
              "      <td>0.470174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.203331</td>\n",
              "      <td>0.450922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.218759</td>\n",
              "      <td>0.467716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.289918</td>\n",
              "      <td>0.538440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.211986</td>\n",
              "      <td>0.460419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.183675</td>\n",
              "      <td>0.428574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.237528</td>\n",
              "      <td>0.487368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.181819</td>\n",
              "      <td>0.426402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.197127</td>\n",
              "      <td>0.443989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.239832</td>\n",
              "      <td>0.489727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.220370</td>\n",
              "      <td>0.469436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.212967</td>\n",
              "      <td>0.461484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.041200</td>\n",
              "      <td>0.205851</td>\n",
              "      <td>0.453708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.041200</td>\n",
              "      <td>0.219911</td>\n",
              "      <td>0.468947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 51:31, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.497201</td>\n",
              "      <td>0.705125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.419870</td>\n",
              "      <td>0.647974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.407016</td>\n",
              "      <td>0.637978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.495557</td>\n",
              "      <td>0.703958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.412947</td>\n",
              "      <td>0.642610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.472959</td>\n",
              "      <td>0.687720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.442307</td>\n",
              "      <td>0.665062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.498299</td>\n",
              "      <td>0.705903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.385750</td>\n",
              "      <td>0.621088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.415177</td>\n",
              "      <td>0.644342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.446184</td>\n",
              "      <td>0.667970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.315334</td>\n",
              "      <td>0.561546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.397304</td>\n",
              "      <td>0.630320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.560082</td>\n",
              "      <td>0.748387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.448152</td>\n",
              "      <td>0.669442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.543001</td>\n",
              "      <td>0.736886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.421573</td>\n",
              "      <td>0.649287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.485191</td>\n",
              "      <td>0.696556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.413935</td>\n",
              "      <td>0.643378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.371265</td>\n",
              "      <td>0.609315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.479328</td>\n",
              "      <td>0.692335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.469174</td>\n",
              "      <td>0.684963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.431512</td>\n",
              "      <td>0.656896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.450710</td>\n",
              "      <td>0.671349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.025600</td>\n",
              "      <td>0.458984</td>\n",
              "      <td>0.677483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 49:48, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.465198</td>\n",
              "      <td>0.682055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.447098</td>\n",
              "      <td>0.668654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.449563</td>\n",
              "      <td>0.670495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.561323</td>\n",
              "      <td>0.749215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.486800</td>\n",
              "      <td>0.501666</td>\n",
              "      <td>0.708284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.486800</td>\n",
              "      <td>0.281255</td>\n",
              "      <td>0.530335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.486800</td>\n",
              "      <td>0.297267</td>\n",
              "      <td>0.545222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.486800</td>\n",
              "      <td>0.388280</td>\n",
              "      <td>0.623121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.486800</td>\n",
              "      <td>0.299656</td>\n",
              "      <td>0.547408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.273259</td>\n",
              "      <td>0.522741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.279169</td>\n",
              "      <td>0.528365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.264797</td>\n",
              "      <td>0.514585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.267330</td>\n",
              "      <td>0.517039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.305574</td>\n",
              "      <td>0.552788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.279648</td>\n",
              "      <td>0.528818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.278387</td>\n",
              "      <td>0.527624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.279666</td>\n",
              "      <td>0.528834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.296124</td>\n",
              "      <td>0.544173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.303972</td>\n",
              "      <td>0.551337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.058700</td>\n",
              "      <td>0.308856</td>\n",
              "      <td>0.555748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.058700</td>\n",
              "      <td>0.299634</td>\n",
              "      <td>0.547388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 51:51, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.587788</td>\n",
              "      <td>0.766673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.640295</td>\n",
              "      <td>0.800184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.582206</td>\n",
              "      <td>0.763025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.994795</td>\n",
              "      <td>0.997394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>0.858986</td>\n",
              "      <td>0.926815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>0.552807</td>\n",
              "      <td>0.743510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>1.415411</td>\n",
              "      <td>1.189710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>0.800559</td>\n",
              "      <td>0.894739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>0.655264</td>\n",
              "      <td>0.809484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.988455</td>\n",
              "      <td>0.994211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.810888</td>\n",
              "      <td>0.900493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.763274</td>\n",
              "      <td>0.873655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.667618</td>\n",
              "      <td>0.817079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.783672</td>\n",
              "      <td>0.885252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>0.826053</td>\n",
              "      <td>0.908875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>0.882458</td>\n",
              "      <td>0.939393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>0.831313</td>\n",
              "      <td>0.911764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>0.782307</td>\n",
              "      <td>0.884481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>0.815151</td>\n",
              "      <td>0.902857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>0.796952</td>\n",
              "      <td>0.892722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>0.846476</td>\n",
              "      <td>0.920041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 51:03, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.451322</td>\n",
              "      <td>0.671805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.355513</td>\n",
              "      <td>0.596249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.690976</td>\n",
              "      <td>0.831250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.285940</td>\n",
              "      <td>0.534734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.267135</td>\n",
              "      <td>0.516851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.303215</td>\n",
              "      <td>0.550650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.284082</td>\n",
              "      <td>0.532993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.267534</td>\n",
              "      <td>0.517237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.496800</td>\n",
              "      <td>0.277611</td>\n",
              "      <td>0.526888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.334055</td>\n",
              "      <td>0.577975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.258248</td>\n",
              "      <td>0.508181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.301945</td>\n",
              "      <td>0.549495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.310617</td>\n",
              "      <td>0.557330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.261007</td>\n",
              "      <td>0.510889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.318132</td>\n",
              "      <td>0.564032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.294734</td>\n",
              "      <td>0.542894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.286997</td>\n",
              "      <td>0.535721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.290979</td>\n",
              "      <td>0.539425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.302785</td>\n",
              "      <td>0.550259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.052100</td>\n",
              "      <td>0.294678</td>\n",
              "      <td>0.542842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.052100</td>\n",
              "      <td>0.294424</td>\n",
              "      <td>0.542609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 51:35, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.988877</td>\n",
              "      <td>0.994423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.733224</td>\n",
              "      <td>0.856285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.664073</td>\n",
              "      <td>0.814907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.484880</td>\n",
              "      <td>0.696333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.460513</td>\n",
              "      <td>0.678611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.648677</td>\n",
              "      <td>0.805405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.601227</td>\n",
              "      <td>0.775389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.482448</td>\n",
              "      <td>0.694585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.459541</td>\n",
              "      <td>0.677895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.426604</td>\n",
              "      <td>0.653149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.459502</td>\n",
              "      <td>0.677866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.440775</td>\n",
              "      <td>0.663909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.452361</td>\n",
              "      <td>0.672578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.458693</td>\n",
              "      <td>0.677269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.458299</td>\n",
              "      <td>0.676978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.435629</td>\n",
              "      <td>0.660022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.425925</td>\n",
              "      <td>0.652629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.437416</td>\n",
              "      <td>0.661374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.427177</td>\n",
              "      <td>0.653588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.434599</td>\n",
              "      <td>0.659242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.443584</td>\n",
              "      <td>0.666021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.434070</td>\n",
              "      <td>0.658840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.439370</td>\n",
              "      <td>0.662850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.434301</td>\n",
              "      <td>0.659015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.437829</td>\n",
              "      <td>0.661686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!mkdir content wording\n",
        "for target in [\"content\", \"wording\"]:\n",
        "    train_by_fold(\n",
        "        train,\n",
        "        model_name=CFG.model_name,\n",
        "        save_each_model=True,\n",
        "        target=target,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "        num_train_epochs=CFG.num_train_epochs,\n",
        "        n_splits=CFG.n_splits,\n",
        "        batch_size=CFG.batch_size,\n",
        "        save_steps=CFG.save_steps,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-AH51-tVvXUm"
      },
      "outputs": [],
      "source": [
        "# !cp -r . /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QSQIR9klJ-bU"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  import json\n",
        "  from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "  def dataset_upload():\n",
        "      global USERID, EX_NO, UPLOAD_DIR\n",
        "      id = f'{USERID}/{EX_NO}'\n",
        "      dataset_metadata = {}\n",
        "      dataset_metadata['id'] = id\n",
        "      dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
        "      dataset_metadata['title'] = f'{TITLE}'\n",
        "      with open(UPLOAD_DIR + 'dataset-metadata.json', 'w') as f:\n",
        "          json.dump(dataset_metadata, f, indent=4)\n",
        "      api = KaggleApi()\n",
        "      api.authenticate()\n",
        "      # データセットがない場合\n",
        "      if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
        "          api.dataset_create_new(folder=UPLOAD_DIR,\n",
        "                                convert_to_csv=False,\n",
        "                                dir_mode='skip'\n",
        "                                #dir_mode='zip'\n",
        "                                )\n",
        "      # データセットがある場合\n",
        "      else:\n",
        "          api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "                                    version_notes='update',\n",
        "                                    convert_to_csv=False,\n",
        "                                    delete_old_versions=True,\n",
        "                                    dir_mode='skip'\n",
        "                                    #dir_mode='zip'\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KAY_Cyy2KEtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c22063-da67-41f8-9bd4-acfe9c9b97e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/another-bert/ (stored 0%)\n",
            "  adding: content/another-bert/fold_3/ (stored 0%)\n",
            "  adding: content/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_3/pytorch_model.bin (deflated 24%)\n",
            "  adding: content/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_1/ (stored 0%)\n",
            "  adding: content/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_1/pytorch_model.bin (deflated 24%)\n",
            "  adding: content/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_2/ (stored 0%)\n",
            "  adding: content/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_2/pytorch_model.bin (deflated 24%)\n",
            "  adding: content/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_0/ (stored 0%)\n",
            "  adding: content/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_0/pytorch_model.bin (deflated 24%)\n",
            "  adding: content/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/ (stored 0%)\n",
            "  adding: wording/another-bert/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_3/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_3/pytorch_model.bin (deflated 24%)\n",
            "  adding: wording/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_1/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_1/pytorch_model.bin (deflated 24%)\n",
            "  adding: wording/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_2/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_2/pytorch_model.bin (deflated 24%)\n",
            "  adding: wording/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_0/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_0/pytorch_model.bin (deflated 24%)\n",
            "  adding: wording/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: pickled.pkl (deflated 72%)\n",
            "CPU times: user 7.56 s, sys: 1.28 s, total: 8.84 s\n",
            "Wall time: 33min 33s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl\n",
        "  # !zip -r ./tmp/output  pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uRAl0v_YKGu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd91e68c-c866-43da-fbe4-ca1397da417e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting upload for file output.zip\n",
            "Upload successful: output.zip (10GB)\n",
            "CPU times: user 188 ms, sys: 7.81 ms, total: 196 ms\n",
            "Wall time: 4.31 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'commitlit-deberta-v3-large-misspel3'\n",
        "  EX_NO = 'commitlit-deberta-v3-large-misspel3'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE56wqWxtltT"
      },
      "outputs": [],
      "source": [
        "!cp -r ./tmp /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hES5LiE3KNM6"
      },
      "source": [
        "## terminate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXEs3uuDKMG-"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64N212Z7MdTD"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    train = validate(\n",
        "        train,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )\n",
        "\n",
        "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
        "    print(f\"cv {target} rmse: {rmse}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3d_usthVu6c"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    test = predict(\n",
        "        test,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e991A_my4RXY"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWdD32Q8nws"
      },
      "source": [
        "## upload dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzr6yQHa8nBA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRl6J7Y28ySx"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   !mkdir tmp\n",
        "#   !zip -r ./tmp/output content wording pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWzbYTkq86KK"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   TITLE = 'devert-v3-trained'\n",
        "#   EX_NO = 'commitlit-2023'  # 実験番号などを入れる、folderのpathにする\n",
        "#   USERID = 'aruaru0'\n",
        "#   UPLOAD_DIR = './tmp/'\n",
        "#   dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y04vF_2m4RXY"
      },
      "source": [
        "## LGBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NFgHw004RXY"
      },
      "outputs": [],
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\"\n",
        "               ] + targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8X4hieY4RXY"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "            'boosting_type': 'gbdt',\n",
        "            'random_state': 42,\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'learning_rate': 0.048,\n",
        "            'max_depth': 3,\n",
        "            'lambda_l1': 0.0,\n",
        "            'lambda_l2': 0.011\n",
        "        }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zGTNAJKtVEf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lgbm.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4by6kkuhOx"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl lgbm.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9XwAvJnukQL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'roberta-base-trained'\n",
        "  EX_NO = 'roberta-base-trained'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulmFlbGJ4RXY"
      },
      "source": [
        "## CV Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTj7OaLm4RXY"
      },
      "outputs": [],
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlVSzuh64RXY"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9NjgA4Z4RXY"
      },
      "outputs": [],
      "source": [
        "drop_columns = [\n",
        "                #\"fold\",\n",
        "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\n",
        "                \"input\"\n",
        "               ] + [\n",
        "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ] + [\n",
        "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahmlT0hs4RXY"
      },
      "outputs": [],
      "source": [
        "pred_dict = {}\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "    preds = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = test.drop(columns=drop_columns)\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "        preds.append(pred)\n",
        "\n",
        "    pred_dict[target] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Y5dzYt4RXY"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "    preds = pred_dict[target]\n",
        "    for i, pred in enumerate(preds):\n",
        "        test[f\"{target}_pred_{i}\"] = pred\n",
        "\n",
        "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqg9H2uB4RXZ"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58Z_kETy4RXZ"
      },
      "source": [
        "## Create Submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS92zy2v4RXZ"
      },
      "outputs": [],
      "source": [
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIOwTOkaHg7m"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tiflhys4RXZ"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2sQz_YD4RXZ"
      },
      "source": [
        "## Summary\n",
        "\n",
        "CV result is like this.\n",
        "\n",
        "| | content rmse |wording rmse | mcrmse | LB| |\n",
        "| -- | -- | -- | -- | -- | -- |\n",
        "|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n",
        "| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n",
        "| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n",
        "| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n",
        "| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n",
        "\n",
        "The CV values improved slightly, and the LB value is improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8HNdBZX4RXZ"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR64NiYA4RXZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx3MwlI24RXZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}