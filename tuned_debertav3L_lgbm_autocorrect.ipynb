{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/CommonLit-Evaluate-Student-Summaries/blob/main/tuned_debertav3L_lgbm_autocorrect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FkXnqfL4Vd0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_917tB4eGO",
        "outputId": "83c58723-5bb5-44a8-affc-d0bf1e49630d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hSZqxM34hSK"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  !mkdir -p /root/.kaggle\n",
        "  !cp /content/drive/MyDrive/Kaggle/kaggle.json  /root/.kaggle/\n",
        "  !chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgkYiHO4qhy",
        "outputId": "4d673aa4-5fa2-4df4-e486-a096da81c68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install kaggle\n",
        "  !apt install unzip\n",
        "  !mkdir input output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5vNe0z44tmh",
        "outputId": "d571623f-5500-4df7-e079-f1e891c36627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\n",
            "\r100% 1.05M/1.05M [00:00<00:00, 178MB/s]\n",
            "Archive:  commonlit-evaluate-student-summaries.zip\n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/prompts_train.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/sample_submission.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_test.csv  \n",
            "  inflating: input/commonlit-evaluate-student-summaries/summaries_train.csv  \n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !kaggle competitions download -c commonlit-evaluate-student-summaries\n",
        "  !unzip -o commonlit-evaluate-student-summaries.zip -d input/commonlit-evaluate-student-summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aCDfcTM6l1n",
        "outputId": "a2c5db86-3b26-46fc-9f8a-d74e4d077ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting autocorrect==2.6\n",
            "  Downloading autocorrect-2.6.0.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.6/622.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.0-py3-none-any.whl size=622231 sha256=b68f5b3f24fa637a0f6f4340170aa7d4c5c0ab001ae564943f409aad82745dfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/66/c6/7470703fc0cd7739a9bbfd7bf8d2b42b2df4eeeca5be85ad7a\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.0\n",
            "Collecting pyspellchecker==0.7.2\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install transformers\n",
        "  !pip install datasets\n",
        "  !pip install sentencepiece\n",
        "  !pip install autocorrect==2.6\n",
        "  !pip install pyspellchecker==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owJ9XYkWC33k",
        "outputId": "cba5fba7-cc4f-4000-8330-464ce5c9f832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-_f_3f5ox\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-_f_3f5ox\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 5ae611118057232f441055f7ef9ba0b0f2b8d533\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.24.0.dev0) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.24.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.24.0.dev0-py3-none-any.whl size=258568 sha256=4ec33385d475df64dc5d622312e4a4f34d8c1c6834676024401f8faa88014967\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qtjw3ry6/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.0.dev0\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  !pip install git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_dxr0ku-Vw8"
      },
      "source": [
        "# ここでランタイムの再起動が必要！！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtdyP9QL7hFs",
        "outputId": "4eb78a31-dfbd-4618-dd71-4870d92fd5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/output\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "is_colab = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  is_colab = True\n",
        "\n",
        "if is_colab:\n",
        "  %cd output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "a800ea21be7f4d638647956ceb72c85f",
            "6d8a2be01e66453c8cc260cd3a8af487",
            "fda292bad301420087d46a8e1dc52f35",
            "f6617472aa554594b0268946475b7812",
            "a979377ac7b54651b9415dc9f8286ddb",
            "4d27bd4a706a4f1f80ef2ac74ec9e7bc",
            "65a5c6ab92564536acea8dad9cf31f37",
            "6e598b898a5d4da39e6ed934b6503f7e",
            "40696edc73094d0184e9898c7d28c895",
            "b568f390f4a84d4ab2f6c30dc6b5dbe0",
            "6c82181a95c24da4967585404965b27e",
            "0e4eb60f66d0433cafd7532f4508a70f",
            "cd2b9694f1604e2c81ca3b71044fbe69",
            "c23e5cc124e6403ebe2f79215fd60ebc",
            "d254f17d05084fcabb003262c58447b5",
            "7e17b21c59b44c51bda170627179cc18",
            "0bfe2a8acf204a8c9ebd9047eef7104e",
            "2190d9305c4a47048e547d71d81153e4",
            "2e194c8d95854cc68a65e443a8f15448",
            "1c0ea608f2bb4983936e1de0e596fd3e",
            "b674af9681034136a8177c59c2bfb6a7",
            "f34af6f6a4904b0fbaf1655345940587",
            "7d38f67799e0486ca99474a27b4943f2",
            "d340babc3f004cc3abce66a84328d475",
            "159d802be6854682aee6695ca655ea02",
            "996e1634d09543f0b14ee40c3d461908",
            "0d28234becb042e6a0b5bdf6f92aee7d",
            "b717b9f6fb9340518ab51513189998e0",
            "bccf7f7b4ba042529a9713e0cd4e8869",
            "d6c549a7740c475ba98d7a3544457787",
            "0a93fd4a9d1a465daf3bdf056d284fb8",
            "26fd2619a7ed4b2a97fe3836f71f9a1f",
            "c6b046d34a0f45fda1671d256b6c30ec",
            "62407ad83689406dac8820f30045af44",
            "bb76df9d1d2b41029fd00de40a415f7a",
            "b2387e1dec8f418aa8d6b66be233de48",
            "ced144bea4684665a7753b8b03fb45fd",
            "e9a3907547a4467a9d4f3b0b5b3122c2",
            "74a6c6f67a12429aaed2505f90304a47",
            "e41554cdf57041b29c01f2998b9f8b40",
            "87c0e4aeb32c41dd97ee9c950095187b",
            "0b9ae5b9399f4300bbaa9040d39d594b",
            "3a649b271f054b7ab7b3324fc9a80450",
            "9b864647d0994192b9727b9175073860"
          ]
        },
        "id": "EdROKpaD7DWX",
        "outputId": "7c03c8bd-9faf-4b38-d274-8e023aa35b54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a800ea21be7f4d638647956ceb72c85f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e4eb60f66d0433cafd7532f4508a70f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d38f67799e0486ca99474a27b4943f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62407ad83689406dac8820f30045af44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "  model_name = \"microsoft/deberta-v3-large\"\n",
        "  # model_name = \"roberta-base\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  hidden_dropout_prob=0.007\n",
        "  attention_probs_dropout_prob=0.007\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "  model_dir = \"../input/another-bert\"\n",
        "  model.save_pretrained(model_dir)\n",
        "  tokenizer.save_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BFTn4SLsclH",
        "outputId": "ebb7a092-c130-4017-9ca2-f4abc9c9e805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deberta.embeddings.word_embeddings.weight True\n",
            "deberta.embeddings.LayerNorm.weight True\n",
            "deberta.embeddings.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.0.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.0.attention.output.dense.weight True\n",
            "deberta.encoder.layer.0.attention.output.dense.bias True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.0.intermediate.dense.weight True\n",
            "deberta.encoder.layer.0.intermediate.dense.bias True\n",
            "deberta.encoder.layer.0.output.dense.weight True\n",
            "deberta.encoder.layer.0.output.dense.bias True\n",
            "deberta.encoder.layer.0.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.0.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.1.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.1.attention.output.dense.weight True\n",
            "deberta.encoder.layer.1.attention.output.dense.bias True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.1.intermediate.dense.weight True\n",
            "deberta.encoder.layer.1.intermediate.dense.bias True\n",
            "deberta.encoder.layer.1.output.dense.weight True\n",
            "deberta.encoder.layer.1.output.dense.bias True\n",
            "deberta.encoder.layer.1.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.1.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.2.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.2.attention.output.dense.weight True\n",
            "deberta.encoder.layer.2.attention.output.dense.bias True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.2.intermediate.dense.weight True\n",
            "deberta.encoder.layer.2.intermediate.dense.bias True\n",
            "deberta.encoder.layer.2.output.dense.weight True\n",
            "deberta.encoder.layer.2.output.dense.bias True\n",
            "deberta.encoder.layer.2.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.2.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.3.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.3.attention.output.dense.weight True\n",
            "deberta.encoder.layer.3.attention.output.dense.bias True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.3.intermediate.dense.weight True\n",
            "deberta.encoder.layer.3.intermediate.dense.bias True\n",
            "deberta.encoder.layer.3.output.dense.weight True\n",
            "deberta.encoder.layer.3.output.dense.bias True\n",
            "deberta.encoder.layer.3.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.3.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.4.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.4.attention.output.dense.weight True\n",
            "deberta.encoder.layer.4.attention.output.dense.bias True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.4.intermediate.dense.weight True\n",
            "deberta.encoder.layer.4.intermediate.dense.bias True\n",
            "deberta.encoder.layer.4.output.dense.weight True\n",
            "deberta.encoder.layer.4.output.dense.bias True\n",
            "deberta.encoder.layer.4.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.4.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.5.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.5.attention.output.dense.weight True\n",
            "deberta.encoder.layer.5.attention.output.dense.bias True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.5.intermediate.dense.weight True\n",
            "deberta.encoder.layer.5.intermediate.dense.bias True\n",
            "deberta.encoder.layer.5.output.dense.weight True\n",
            "deberta.encoder.layer.5.output.dense.bias True\n",
            "deberta.encoder.layer.5.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.5.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.6.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.6.attention.output.dense.weight True\n",
            "deberta.encoder.layer.6.attention.output.dense.bias True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.6.intermediate.dense.weight True\n",
            "deberta.encoder.layer.6.intermediate.dense.bias True\n",
            "deberta.encoder.layer.6.output.dense.weight True\n",
            "deberta.encoder.layer.6.output.dense.bias True\n",
            "deberta.encoder.layer.6.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.6.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.7.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.7.attention.output.dense.weight True\n",
            "deberta.encoder.layer.7.attention.output.dense.bias True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.7.intermediate.dense.weight True\n",
            "deberta.encoder.layer.7.intermediate.dense.bias True\n",
            "deberta.encoder.layer.7.output.dense.weight True\n",
            "deberta.encoder.layer.7.output.dense.bias True\n",
            "deberta.encoder.layer.7.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.7.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.8.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.8.attention.output.dense.weight True\n",
            "deberta.encoder.layer.8.attention.output.dense.bias True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.8.intermediate.dense.weight True\n",
            "deberta.encoder.layer.8.intermediate.dense.bias True\n",
            "deberta.encoder.layer.8.output.dense.weight True\n",
            "deberta.encoder.layer.8.output.dense.bias True\n",
            "deberta.encoder.layer.8.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.8.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.9.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.9.attention.output.dense.weight True\n",
            "deberta.encoder.layer.9.attention.output.dense.bias True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.9.intermediate.dense.weight True\n",
            "deberta.encoder.layer.9.intermediate.dense.bias True\n",
            "deberta.encoder.layer.9.output.dense.weight True\n",
            "deberta.encoder.layer.9.output.dense.bias True\n",
            "deberta.encoder.layer.9.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.9.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.10.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.10.attention.output.dense.weight True\n",
            "deberta.encoder.layer.10.attention.output.dense.bias True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.10.intermediate.dense.weight True\n",
            "deberta.encoder.layer.10.intermediate.dense.bias True\n",
            "deberta.encoder.layer.10.output.dense.weight True\n",
            "deberta.encoder.layer.10.output.dense.bias True\n",
            "deberta.encoder.layer.10.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.10.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.11.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.11.attention.output.dense.weight True\n",
            "deberta.encoder.layer.11.attention.output.dense.bias True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.11.intermediate.dense.weight True\n",
            "deberta.encoder.layer.11.intermediate.dense.bias True\n",
            "deberta.encoder.layer.11.output.dense.weight True\n",
            "deberta.encoder.layer.11.output.dense.bias True\n",
            "deberta.encoder.layer.11.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.11.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.12.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.12.attention.output.dense.weight True\n",
            "deberta.encoder.layer.12.attention.output.dense.bias True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.12.intermediate.dense.weight True\n",
            "deberta.encoder.layer.12.intermediate.dense.bias True\n",
            "deberta.encoder.layer.12.output.dense.weight True\n",
            "deberta.encoder.layer.12.output.dense.bias True\n",
            "deberta.encoder.layer.12.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.12.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.13.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.13.attention.output.dense.weight True\n",
            "deberta.encoder.layer.13.attention.output.dense.bias True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.13.intermediate.dense.weight True\n",
            "deberta.encoder.layer.13.intermediate.dense.bias True\n",
            "deberta.encoder.layer.13.output.dense.weight True\n",
            "deberta.encoder.layer.13.output.dense.bias True\n",
            "deberta.encoder.layer.13.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.13.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.14.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.14.attention.output.dense.weight True\n",
            "deberta.encoder.layer.14.attention.output.dense.bias True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.14.intermediate.dense.weight True\n",
            "deberta.encoder.layer.14.intermediate.dense.bias True\n",
            "deberta.encoder.layer.14.output.dense.weight True\n",
            "deberta.encoder.layer.14.output.dense.bias True\n",
            "deberta.encoder.layer.14.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.14.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.15.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.15.attention.output.dense.weight True\n",
            "deberta.encoder.layer.15.attention.output.dense.bias True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.15.intermediate.dense.weight True\n",
            "deberta.encoder.layer.15.intermediate.dense.bias True\n",
            "deberta.encoder.layer.15.output.dense.weight True\n",
            "deberta.encoder.layer.15.output.dense.bias True\n",
            "deberta.encoder.layer.15.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.15.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.16.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.16.attention.output.dense.weight True\n",
            "deberta.encoder.layer.16.attention.output.dense.bias True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.16.intermediate.dense.weight True\n",
            "deberta.encoder.layer.16.intermediate.dense.bias True\n",
            "deberta.encoder.layer.16.output.dense.weight True\n",
            "deberta.encoder.layer.16.output.dense.bias True\n",
            "deberta.encoder.layer.16.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.16.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.17.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.17.attention.output.dense.weight True\n",
            "deberta.encoder.layer.17.attention.output.dense.bias True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.17.intermediate.dense.weight True\n",
            "deberta.encoder.layer.17.intermediate.dense.bias True\n",
            "deberta.encoder.layer.17.output.dense.weight True\n",
            "deberta.encoder.layer.17.output.dense.bias True\n",
            "deberta.encoder.layer.17.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.17.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.18.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.18.attention.output.dense.weight True\n",
            "deberta.encoder.layer.18.attention.output.dense.bias True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.18.intermediate.dense.weight True\n",
            "deberta.encoder.layer.18.intermediate.dense.bias True\n",
            "deberta.encoder.layer.18.output.dense.weight True\n",
            "deberta.encoder.layer.18.output.dense.bias True\n",
            "deberta.encoder.layer.18.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.18.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.19.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.19.attention.output.dense.weight True\n",
            "deberta.encoder.layer.19.attention.output.dense.bias True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.19.intermediate.dense.weight True\n",
            "deberta.encoder.layer.19.intermediate.dense.bias True\n",
            "deberta.encoder.layer.19.output.dense.weight True\n",
            "deberta.encoder.layer.19.output.dense.bias True\n",
            "deberta.encoder.layer.19.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.19.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.20.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.20.attention.output.dense.weight True\n",
            "deberta.encoder.layer.20.attention.output.dense.bias True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.20.intermediate.dense.weight True\n",
            "deberta.encoder.layer.20.intermediate.dense.bias True\n",
            "deberta.encoder.layer.20.output.dense.weight True\n",
            "deberta.encoder.layer.20.output.dense.bias True\n",
            "deberta.encoder.layer.20.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.20.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.21.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.21.attention.output.dense.weight True\n",
            "deberta.encoder.layer.21.attention.output.dense.bias True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.21.intermediate.dense.weight True\n",
            "deberta.encoder.layer.21.intermediate.dense.bias True\n",
            "deberta.encoder.layer.21.output.dense.weight True\n",
            "deberta.encoder.layer.21.output.dense.bias True\n",
            "deberta.encoder.layer.21.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.21.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.22.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.22.attention.output.dense.weight True\n",
            "deberta.encoder.layer.22.attention.output.dense.bias True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.22.intermediate.dense.weight True\n",
            "deberta.encoder.layer.22.intermediate.dense.bias True\n",
            "deberta.encoder.layer.22.output.dense.weight True\n",
            "deberta.encoder.layer.22.output.dense.bias True\n",
            "deberta.encoder.layer.22.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.22.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.query_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.key_proj.bias True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.weight True\n",
            "deberta.encoder.layer.23.attention.self.value_proj.bias True\n",
            "deberta.encoder.layer.23.attention.output.dense.weight True\n",
            "deberta.encoder.layer.23.attention.output.dense.bias True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.attention.output.LayerNorm.bias True\n",
            "deberta.encoder.layer.23.intermediate.dense.weight True\n",
            "deberta.encoder.layer.23.intermediate.dense.bias True\n",
            "deberta.encoder.layer.23.output.dense.weight True\n",
            "deberta.encoder.layer.23.output.dense.bias True\n",
            "deberta.encoder.layer.23.output.LayerNorm.weight True\n",
            "deberta.encoder.layer.23.output.LayerNorm.bias True\n",
            "deberta.encoder.rel_embeddings.weight True\n",
            "deberta.encoder.LayerNorm.weight True\n",
            "deberta.encoder.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        " # You can confirm which layers have been frozen and see the whole layer struct of the model\n",
        " for n, p in model.named_parameters():\n",
        "    print(n, p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edsSr0fIs2y2"
      },
      "outputs": [],
      "source": [
        "def top_half_layer_freeze(model):\n",
        "    for i in range(0,6,1):\n",
        "        for n,p in model.named_parameters():\n",
        "            if f'encoder.layer.{i}.' in n:\n",
        "                p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OcffOfUs4OC"
      },
      "outputs": [],
      "source": [
        "top_half_layer_freeze(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMpRe4l5AO_P",
        "outputId": "3433ccc4-f961-4d84-99bf-ac68444c6e75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnE6iEp4RXS"
      },
      "source": [
        "# Notes\n",
        "This is a slightly tuned version of @nogawanogawa 's work and I have also converted his messages to english here you can find his notebook here https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-spell-autocorrect please give him kudos for sharing his efforts\n",
        "\n",
        "### Things I would expect there to be a number of things that will allow this model to preform better outside of just strategy and more data. I would imagine there are a few more tuning parameters that could help this model go a long way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this notebook a combonation of Deberta and LGBM is used, pyspellchecker is also used in order to correct some of the spelling mistakes that are discussed in the discussions tab\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "[my previous notebook](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering)\n",
        "[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n",
        "\n",
        "The primary goal of this notebook is to enhance the overall score by honing in on the issue of \"misspellings.\"\n",
        "\n",
        "## Main Concept\n",
        "\n",
        "The Transformers model I'm currently utilizing, Deberta, is pretrained on \"correct sentences.\" However, if I were to train and input it with sentences containing misspellings, Deberta's ability to understand meaning might be compromised.\n",
        "\n",
        "From a human evaluator's perspective, detecting misspellings would prompt deductions in scores. After discreetly rectifying the misspelled words, I'd proceed to evaluate other textual facets. If we assume the scoring process aligns with this approach, it's conceivable that tallying and **correcting** misspellings before feeding text into Deberta could enable the model to aptly capture features beyond just misspellings.\n",
        "\n",
        "In this notebook, I will embark on the journey of auto-correcting misspelled words before inputting them into Deberta. The aim is to evaluate the model's performance by distinctly isolating misspellings from other aspects.\n",
        "\n",
        "### Feature Engineering\n",
        "\n",
        "I intend to largely retain the same features as before:\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - Count\n",
        "  - Ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - Spelling: pyspellchecker\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "I plan to construct a model with the architecture depicted in the following diagram. For the input to Deberta (`text`), I will pre-process by correcting any misspellings. In other aspects of feature engineering, I will utilize the `text` as is.\n",
        "\n",
        "### References\n",
        "\n",
        "- https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941\n",
        "\n",
        "### My previous notebooks\n",
        "\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-with-llama2-example\n",
        "- https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3e8TQJd4RXU"
      },
      "outputs": [],
      "source": [
        "if not is_colab :\n",
        "  !pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
        "  !pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkGQJ0tu4RXV"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset,load_dataset, load_from_disk\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric, disable_progress_bar\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "from autocorrect import Speller\n",
        "from spellchecker import SpellChecker\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTSJWXAjvRa",
        "outputId": "6da55c57-0a50-4afd-8aa2-72bc6f4ecfbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu= 8\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "cpu_num = multiprocessing.cpu_count()\n",
        "print(\"cpu=\", cpu_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwl4vqgbjyBh"
      },
      "outputs": [],
      "source": [
        "seed_base = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-pPPJ3a4RXV"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=seed_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfBN_xxH4RXW"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name=\"another-bert\"\n",
        "    learning_rate=1.5e-5\n",
        "    weight_decay=0.02\n",
        "    hidden_dropout_prob=0.007\n",
        "    attention_probs_dropout_prob=0.007\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=3\n",
        "\n",
        "    random_seed=seed_base\n",
        "    save_steps=100\n",
        "    max_length=512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzSk2kRA4RXW"
      },
      "source": [
        "## Dataload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3nYzKoi4RXW"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"../input/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2huhIeJ4RXW"
      },
      "source": [
        "## Preprocess\n",
        "\n",
        "[Using features]\n",
        "\n",
        "- Text Length\n",
        "- Length Ratio\n",
        "- Word Overlap\n",
        "- N-grams Co-occurrence\n",
        "  - count\n",
        "  - ratio\n",
        "- Quotes Overlap\n",
        "- Grammar Check\n",
        "  - spelling: pyspellchecker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7F-j8-I_e18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hESbPb6N4RXW"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                ) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.twd = TreebankWordDetokenizer()\n",
        "        self.STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
        "        self.speller = Speller(lang='en')\n",
        "        self.spellchecker = SpellChecker()\n",
        "\n",
        "    def word_overlap_count(self, row):\n",
        "        \"\"\" intersection(prompt_text, text) \"\"\"\n",
        "        def check_is_stop_word(word):\n",
        "            return word in self.STOP_WORDS\n",
        "\n",
        "        prompt_words = row['prompt_tokens']\n",
        "        summary_words = row['summary_tokens']\n",
        "        if self.STOP_WORDS:\n",
        "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
        "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
        "        return len(set(prompt_words).intersection(set(summary_words)))\n",
        "\n",
        "    def ngrams(self, token, n):\n",
        "        # Use the zip function to help us generate n-grams\n",
        "        # Concatentate the tokens into ngrams and return\n",
        "        ngrams = zip(*[token[i:] for i in range(n)])\n",
        "        return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
        "        # Tokenize the original text and summary into words\n",
        "        original_tokens = row['prompt_tokens']\n",
        "        summary_tokens = row['summary_tokens']\n",
        "\n",
        "        # Generate n-grams for the original text and summary\n",
        "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
        "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
        "\n",
        "        # Calculate the number of common n-grams\n",
        "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
        "        return len(common_ngrams)\n",
        "\n",
        "    def ner_overlap_count(self, row, mode:str):\n",
        "        model = self.spacy_ner_model\n",
        "        def clean_ners(ner_list):\n",
        "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
        "        prompt = model(row['prompt_text'])\n",
        "        summary = model(row['text'])\n",
        "\n",
        "        if \"spacy\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
        "        elif \"stanza\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
        "        else:\n",
        "            raise Exception(\"Model not supported\")\n",
        "\n",
        "        prompt_ner = clean_ners(prompt_ner)\n",
        "        summary_ner = clean_ners(summary_ner)\n",
        "\n",
        "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
        "\n",
        "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
        "\n",
        "        if mode == \"train\":\n",
        "            return ner_dict\n",
        "        elif mode == \"test\":\n",
        "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
        "\n",
        "\n",
        "    def quotes_count(self, row):\n",
        "        summary = row['text']\n",
        "        text = row['prompt_text']\n",
        "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
        "        if len(quotes_from_summary)>0:\n",
        "            return [quote in text for quote in quotes_from_summary].count(True)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def spelling(self, text):\n",
        "\n",
        "        wordlist=text.split()\n",
        "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
        "\n",
        "        return amount_miss\n",
        "\n",
        "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
        "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
        "        self.spellchecker.word_frequency.load_words(tokens)\n",
        "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
        "\n",
        "    def run(self,\n",
        "            prompts: pd.DataFrame,\n",
        "            summaries:pd.DataFrame,\n",
        "            mode:str\n",
        "        ) -> pd.DataFrame:\n",
        "\n",
        "        # before merge preprocess\n",
        "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
        "            lambda x: len(word_tokenize(x))\n",
        "        )\n",
        "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
        "            lambda x: word_tokenize(x)\n",
        "        )\n",
        "\n",
        "        # Add prompt tokens into spelling checker dictionary\n",
        "        prompts[\"prompt_tokens\"].apply(\n",
        "            lambda x: self.add_spelling_dictionary(x)\n",
        "        )\n",
        "\n",
        "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "        # fix misspelling\n",
        "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
        "            lambda x: self.speller(x)\n",
        "        )\n",
        "\n",
        "        # count misspelling\n",
        "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
        "\n",
        "        # merge prompts and summaries\n",
        "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
        "\n",
        "        # after merge preprocess\n",
        "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
        "\n",
        "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
        "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence,args=(2,), axis=1\n",
        "        )\n",
        "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
        "\n",
        "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence, args=(3,), axis=1\n",
        "        )\n",
        "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
        "\n",
        "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
        "\n",
        "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
        "\n",
        "preprocessor = Preprocessor(model_name=CFG.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "CJEL4wDV4RXX",
        "outputId": "97d36d04-33c8-49b3-d6d5-78843d7ae378"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7165/7165 [07:06<00:00, 16.80it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 7745.03it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 9232.05it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4634.76it/s]\n",
            "100%|██████████| 7165/7165 [00:01<00:00, 4002.70it/s]\n",
            "100%|██████████| 7165/7165 [00:00<00:00, 71297.85it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7594.94it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10040.23it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 2209.85it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 4017.53it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 2239.95it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3625.15it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-747ea095-99b5-4bac-87ff-85cd4e7c2553\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-747ea095-99b5-4bac-87ff-85cd4e7c2553')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-747ea095-99b5-4bac-87ff-85cd4e7c2553 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-747ea095-99b5-4bac-87ff-85cd4e7c2553');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-785662c0-fe19-49b6-bdc9-6dcf85b74c2b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-785662c0-fe19-49b6-bdc9-6dcf85b74c2b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-785662c0-fe19-49b6-bdc9-6dcf85b74c2b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  \n",
              "0             0  \n",
              "1             0  \n",
              "2             2  \n",
              "3             0  \n",
              "4             4  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
        "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqEJ3DWX4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'wb') as f:\n",
        "    pickle.dump(train, f)\n",
        "    pickle.dump(test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxMtKG9l4RXX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickled.pkl', 'rb') as f:\n",
        "    train = pickle.load(f)\n",
        "    test = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCo_NEhg6SEb"
      },
      "outputs": [],
      "source": [
        "# train = train[:512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "YavvVjbl4RXX",
        "outputId": "aca7566c-57e9-4edc-9c46-a421925f1f87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3460a671-73c6-4934-9e94-1ef26e3fee79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>length_ratio</th>\n",
              "      <th>word_overlap_count</th>\n",
              "      <th>bigram_overlap_count</th>\n",
              "      <th>bigram_overlap_ratio</th>\n",
              "      <th>trigram_overlap_count</th>\n",
              "      <th>trigram_overlap_ratio</th>\n",
              "      <th>quotes_count</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>5</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0.415094</td>\n",
              "      <td>10</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>32</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.086142</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>5</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>5</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>29</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>0.351515</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.116883</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3460a671-73c6-4934-9e94-1ef26e3fee79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3460a671-73c6-4934-9e94-1ef26e3fee79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3460a671-73c6-4934-9e94-1ef26e3fee79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99543478-3ac9-4abe-aa77-1457c079b2c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99543478-3ac9-4abe-aa77-1457c079b2c8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99543478-3ac9-4abe-aa77-1457c079b2c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  \\\n",
              "0  0.205683  0.380538              64   \n",
              "1 -0.548304  0.506755              54   \n",
              "2  3.128928  4.231226             269   \n",
              "3 -0.210614 -0.471415              28   \n",
              "4  3.272894  3.219757             232   \n",
              "\n",
              "                                  fixed_summary_text  splling_err_num  \\\n",
              "0  The third wave was an experimental see how peo...                5   \n",
              "1  They would rub it up with soda to make the sme...                2   \n",
              "2  In Egypt, there were many occupations and soci...               32   \n",
              "3  The highest class was Pharaohs these people we...                5   \n",
              "4  The Third Wave developed  rapidly because the ...               29   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  prompt_length  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "1  With one member trimming beef in a cannery, an...           1076   \n",
              "2  Egyptian society was structured like a pyramid...            625   \n",
              "3  Egyptian society was structured like a pyramid...            625   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...            660   \n",
              "\n",
              "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
              "0      0.096970                  14                     4   \n",
              "1      0.050186                  18                    22   \n",
              "2      0.430400                  22                    52   \n",
              "3      0.044800                   6                     6   \n",
              "4      0.351515                  23                    27   \n",
              "\n",
              "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
              "0              0.063492                      0               0.000000   \n",
              "1              0.415094                     10               0.192308   \n",
              "2              0.194030                     23               0.086142   \n",
              "3              0.222222                      5               0.192308   \n",
              "4              0.116883                      5               0.021739   \n",
              "\n",
              "   quotes_count  fold  \n",
              "0             0   3.0  \n",
              "1             0   2.0  \n",
              "2             2   1.0  \n",
              "3             0   1.0  \n",
              "4             4   3.0  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ40iLxj4RXX"
      },
      "source": [
        "## Model Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6JS7cYm4RXX"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_BYbqcT4RXX"
      },
      "source": [
        "## Deberta Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne-jnegYEw4C"
      },
      "outputs": [],
      "source": [
        "class ContentScoreRegressor:\n",
        "    def __init__(self,\n",
        "                model_name: str,\n",
        "                model_dir: str,\n",
        "                target: str,\n",
        "                hidden_dropout_prob: float,\n",
        "                attention_probs_dropout_prob: float,\n",
        "                max_length: int,\n",
        "                ):\n",
        "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
        "        self.input_col = \"input\"\n",
        "\n",
        "        self.text_cols = [self.input_col]\n",
        "        self.target = target\n",
        "        self.target_cols = [target]\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.model_dir = model_dir\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"../input/{model_name}\")\n",
        "        self.model_config = AutoConfig.from_pretrained(f\"../input/{model_name}\")\n",
        "\n",
        "        self.model_config.update({\n",
        "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
        "            \"num_labels\": 1,\n",
        "            \"problem_type\": \"regression\",\n",
        "        })\n",
        "\n",
        "        seed_everything(seed=42)\n",
        "\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=self.tokenizer\n",
        "        )\n",
        "\n",
        "\n",
        "    def tokenize_function(self, examples: pd.DataFrame):\n",
        "        labels = [examples[self.target]]\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return {\n",
        "            **tokenized,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                         padding=False,\n",
        "                         truncation=True,\n",
        "                         max_length=self.max_length)\n",
        "        return tokenized\n",
        "\n",
        "    def train(self,\n",
        "            fold: int,\n",
        "            train_df: pd.DataFrame,\n",
        "            valid_df: pd.DataFrame,\n",
        "            batch_size: int,\n",
        "            learning_rate: float,\n",
        "            weight_decay: float,\n",
        "            num_train_epochs: float,\n",
        "            save_steps: int,\n",
        "        ) -> None:\n",
        "        \"\"\"fine-tuning\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        train_df[self.input_col] = (\n",
        "                    train_df[\"prompt_title\"] + sep\n",
        "                    + train_df[\"prompt_question\"] + sep\n",
        "                    + train_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        valid_df[self.input_col] = (\n",
        "                    valid_df[\"prompt_title\"] + sep\n",
        "                    + valid_df[\"prompt_question\"] + sep\n",
        "                    + valid_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "\n",
        "        train_df = train_df[[self.input_col] + self.target_cols]\n",
        "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
        "            f\"../input/{self.model_name}\",\n",
        "            config=self.model_config,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        top_half_layer_freeze(model_content)\n",
        "\n",
        "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
        "\n",
        "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
        "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
        "\n",
        "        # eg. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            load_best_model_at_end=True, # select best model\n",
        "            learning_rate=learning_rate,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=4,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            report_to='none',\n",
        "            greater_is_better=False,\n",
        "            save_strategy=\"steps\",\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=save_steps,\n",
        "            save_steps=save_steps,\n",
        "            metric_for_best_model=\"rmse\",\n",
        "            save_total_limit=1,\n",
        "            fp16=True,\n",
        "            warmup_steps = 100,\n",
        "            gradient_accumulation_steps = 4,\n",
        "            dataloader_num_workers = cpu_num,\n",
        "            )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model_content,\n",
        "            args=training_args,\n",
        "            train_dataset=train_tokenized_datasets,\n",
        "            eval_dataset=val_tokenized_datasets,\n",
        "            tokenizer=self.tokenizer,\n",
        "            compute_metrics=compute_metrics,\n",
        "            data_collator=self.data_collator\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        shutil.rmtree(self.model_dir)\n",
        "\n",
        "        model_content.save_pretrained(self.model_dir)\n",
        "        self.tokenizer.save_pretrained(self.model_dir)\n",
        "\n",
        "\n",
        "    def predict(self,\n",
        "                test_df: pd.DataFrame,\n",
        "                fold: int,\n",
        "               ):\n",
        "        \"\"\"predict content score\"\"\"\n",
        "\n",
        "        sep = self.tokenizer.sep_token\n",
        "        in_text = (\n",
        "                    test_df[\"prompt_title\"] + sep\n",
        "                    + test_df[\"prompt_question\"] + sep\n",
        "                    + test_df[\"fixed_summary_text\"]\n",
        "                  )\n",
        "        test_df[self.input_col] = in_text\n",
        "\n",
        "        test_ = test_df[[self.input_col]]\n",
        "\n",
        "        test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n",
        "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
        "\n",
        "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
        "        model_content.eval()\n",
        "\n",
        "        # e.g. \"bert/fold_0/\"\n",
        "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = 4,\n",
        "            dataloader_drop_last = False,\n",
        "        )\n",
        "\n",
        "        # init trainer\n",
        "        infer_content = Trainer(\n",
        "                      model = model_content,\n",
        "                      tokenizer=self.tokenizer,\n",
        "                      data_collator=self.data_collator,\n",
        "                      args = test_args)\n",
        "\n",
        "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-yViAlt4RXX"
      },
      "outputs": [],
      "source": [
        "def train_by_fold(\n",
        "        train_df: pd.DataFrame,\n",
        "        model_name: str,\n",
        "        target:str,\n",
        "        save_each_model: bool,\n",
        "        n_splits: int,\n",
        "        batch_size: int,\n",
        "        learning_rate: int,\n",
        "        hidden_dropout_prob: float,\n",
        "        attention_probs_dropout_prob: float,\n",
        "        weight_decay: float,\n",
        "        num_train_epochs: int,\n",
        "        save_steps: int,\n",
        "        max_length:int\n",
        "    ):\n",
        "\n",
        "    # delete old model files\n",
        "    if os.path.exists(model_name):\n",
        "        shutil.rmtree(model_name)\n",
        "\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        train_data = train_df[train_df[\"fold\"] != fold]\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        csr.train(\n",
        "            fold=fold,\n",
        "            train_df=train_data,\n",
        "            valid_df=valid_data,\n",
        "            batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=weight_decay,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            save_steps=save_steps,\n",
        "        )\n",
        "\n",
        "def validate(\n",
        "    train_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict oof data\"\"\"\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=valid_data,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
        "\n",
        "    return train_df\n",
        "\n",
        "def predict(\n",
        "    test_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    save_each_model: bool,\n",
        "    model_name: str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ):\n",
        "    \"\"\"predict using mean folds\"\"\"\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        if save_each_model == True:\n",
        "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
        "        else:\n",
        "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
        "\n",
        "        csr = ContentScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            target=target,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred = csr.predict(\n",
        "            test_df=test_df,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
        "\n",
        "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
        "\n",
        "    return test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "8twHE2C44RXY",
        "outputId": "68916b9f-efa1-41c4-f900-0311b3103487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 52:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340302</td>\n",
              "      <td>0.583354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.268180</td>\n",
              "      <td>0.517861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.302707</td>\n",
              "      <td>0.550188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.215720</td>\n",
              "      <td>0.464457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.481577</td>\n",
              "      <td>0.693957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.243727</td>\n",
              "      <td>0.493687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.245942</td>\n",
              "      <td>0.495925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.171030</td>\n",
              "      <td>0.413558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.221963</td>\n",
              "      <td>0.471129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.362372</td>\n",
              "      <td>0.601973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.304221</td>\n",
              "      <td>0.551562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.367213</td>\n",
              "      <td>0.605981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.330153</td>\n",
              "      <td>0.574590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.287359</td>\n",
              "      <td>0.536059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.296914</td>\n",
              "      <td>0.544898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.289104</td>\n",
              "      <td>0.537684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.276387</td>\n",
              "      <td>0.525725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.249933</td>\n",
              "      <td>0.499933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.281314</td>\n",
              "      <td>0.530390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.288822</td>\n",
              "      <td>0.537421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.288140</td>\n",
              "      <td>0.536787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 55:44, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.419402</td>\n",
              "      <td>0.647613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.293607</td>\n",
              "      <td>0.541855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.321381</td>\n",
              "      <td>0.566905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.380569</td>\n",
              "      <td>0.616903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.340211</td>\n",
              "      <td>0.583276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.324081</td>\n",
              "      <td>0.569281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.346734</td>\n",
              "      <td>0.588842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.465945</td>\n",
              "      <td>0.682602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.283495</td>\n",
              "      <td>0.532442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.301763</td>\n",
              "      <td>0.549330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.234869</td>\n",
              "      <td>0.484633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.287132</td>\n",
              "      <td>0.535847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.284334</td>\n",
              "      <td>0.533230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.264637</td>\n",
              "      <td>0.514429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.260098</td>\n",
              "      <td>0.509999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.277680</td>\n",
              "      <td>0.526954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.251745</td>\n",
              "      <td>0.501742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.274557</td>\n",
              "      <td>0.523982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.249961</td>\n",
              "      <td>0.499961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.039900</td>\n",
              "      <td>0.276474</td>\n",
              "      <td>0.525808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.039900</td>\n",
              "      <td>0.262738</td>\n",
              "      <td>0.512580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 54:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.250869</td>\n",
              "      <td>0.500868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.224514</td>\n",
              "      <td>0.473829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.213510</td>\n",
              "      <td>0.462072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.357769</td>\n",
              "      <td>0.598138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.328501</td>\n",
              "      <td>0.573150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.231839</td>\n",
              "      <td>0.481496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.344562</td>\n",
              "      <td>0.586994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.199481</td>\n",
              "      <td>0.446633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.202907</td>\n",
              "      <td>0.450452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.184114</td>\n",
              "      <td>0.429085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.236516</td>\n",
              "      <td>0.486329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.197372</td>\n",
              "      <td>0.444266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.174701</td>\n",
              "      <td>0.417973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.251368</td>\n",
              "      <td>0.501366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>0.190427</td>\n",
              "      <td>0.436380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>0.191238</td>\n",
              "      <td>0.437308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>0.202091</td>\n",
              "      <td>0.449545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>0.212906</td>\n",
              "      <td>0.461417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>0.197953</td>\n",
              "      <td>0.444919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.038900</td>\n",
              "      <td>0.201816</td>\n",
              "      <td>0.449240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.038900</td>\n",
              "      <td>0.202660</td>\n",
              "      <td>0.450178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 55:54, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.384498</td>\n",
              "      <td>0.620079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.488611</td>\n",
              "      <td>0.699007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.277373</td>\n",
              "      <td>0.526662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.330814</td>\n",
              "      <td>0.575164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.480981</td>\n",
              "      <td>0.693528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.380324</td>\n",
              "      <td>0.616704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.406267</td>\n",
              "      <td>0.637391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.500895</td>\n",
              "      <td>0.707739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.385317</td>\n",
              "      <td>0.620739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.352443</td>\n",
              "      <td>0.593669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.385268</td>\n",
              "      <td>0.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.351231</td>\n",
              "      <td>0.592647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.450924</td>\n",
              "      <td>0.671508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.511379</td>\n",
              "      <td>0.715108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.348013</td>\n",
              "      <td>0.589926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.607916</td>\n",
              "      <td>0.779690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.374849</td>\n",
              "      <td>0.612249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.416725</td>\n",
              "      <td>0.645542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.393679</td>\n",
              "      <td>0.627438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.301285</td>\n",
              "      <td>0.548895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.397662</td>\n",
              "      <td>0.630604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.416367</td>\n",
              "      <td>0.645265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.359910</td>\n",
              "      <td>0.599925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.370021</td>\n",
              "      <td>0.608294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.025900</td>\n",
              "      <td>0.404578</td>\n",
              "      <td>0.636064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2125/2125 52:16, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.517893</td>\n",
              "      <td>0.719648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.288589</td>\n",
              "      <td>0.537204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.376475</td>\n",
              "      <td>0.613576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.466782</td>\n",
              "      <td>0.683214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.474800</td>\n",
              "      <td>0.351541</td>\n",
              "      <td>0.592909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.474800</td>\n",
              "      <td>0.276879</td>\n",
              "      <td>0.526193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.474800</td>\n",
              "      <td>0.270422</td>\n",
              "      <td>0.520021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.474800</td>\n",
              "      <td>0.360150</td>\n",
              "      <td>0.600125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.474800</td>\n",
              "      <td>0.321782</td>\n",
              "      <td>0.567259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.247400</td>\n",
              "      <td>0.256809</td>\n",
              "      <td>0.506763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.247400</td>\n",
              "      <td>0.259384</td>\n",
              "      <td>0.509297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.247400</td>\n",
              "      <td>0.263672</td>\n",
              "      <td>0.513490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.247400</td>\n",
              "      <td>0.262522</td>\n",
              "      <td>0.512369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.247400</td>\n",
              "      <td>0.270613</td>\n",
              "      <td>0.520205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>0.512602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.278037</td>\n",
              "      <td>0.527292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.273926</td>\n",
              "      <td>0.523380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.278737</td>\n",
              "      <td>0.527956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.272080</td>\n",
              "      <td>0.521613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.049100</td>\n",
              "      <td>0.274482</td>\n",
              "      <td>0.523910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.049100</td>\n",
              "      <td>0.271648</td>\n",
              "      <td>0.521198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2145/2145 54:49, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.621827</td>\n",
              "      <td>0.788560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.761761</td>\n",
              "      <td>0.872789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.193651</td>\n",
              "      <td>1.092543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.889308</td>\n",
              "      <td>0.943031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.850920</td>\n",
              "      <td>0.922453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.597294</td>\n",
              "      <td>0.772848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>1.355576</td>\n",
              "      <td>1.164292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.737081</td>\n",
              "      <td>0.858534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.854388</td>\n",
              "      <td>0.924331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.968541</td>\n",
              "      <td>0.984145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.935033</td>\n",
              "      <td>0.966971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.836953</td>\n",
              "      <td>0.914852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.877742</td>\n",
              "      <td>0.936879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.730843</td>\n",
              "      <td>0.854894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.211380</td>\n",
              "      <td>1.100627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.021588</td>\n",
              "      <td>1.010737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.071828</td>\n",
              "      <td>1.035291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>0.992433</td>\n",
              "      <td>0.996209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.012515</td>\n",
              "      <td>1.006238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.995613</td>\n",
              "      <td>0.997804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>1.049467</td>\n",
              "      <td>1.024435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2150/2150 53:37, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.396884</td>\n",
              "      <td>0.629987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.347931</td>\n",
              "      <td>0.589857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.444158</td>\n",
              "      <td>0.666452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.286378</td>\n",
              "      <td>0.535143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.352168</td>\n",
              "      <td>0.593437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.259809</td>\n",
              "      <td>0.509714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.268992</td>\n",
              "      <td>0.518645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.253634</td>\n",
              "      <td>0.503621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.243111</td>\n",
              "      <td>0.493062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.245440</td>\n",
              "      <td>0.495419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.256691</td>\n",
              "      <td>0.506647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.272392</td>\n",
              "      <td>0.521912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.245220</td>\n",
              "      <td>0.495197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.247688</td>\n",
              "      <td>0.497682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.240803</td>\n",
              "      <td>0.490717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.256472</td>\n",
              "      <td>0.506431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.253465</td>\n",
              "      <td>0.503453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.260324</td>\n",
              "      <td>0.510220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.268615</td>\n",
              "      <td>0.518281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.057200</td>\n",
              "      <td>0.263119</td>\n",
              "      <td>0.512951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.057200</td>\n",
              "      <td>0.253621</td>\n",
              "      <td>0.503608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2525' max='2525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2525/2525 55:22, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.814145</td>\n",
              "      <td>0.902300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.522691</td>\n",
              "      <td>0.722974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.638300</td>\n",
              "      <td>0.798937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.457420</td>\n",
              "      <td>0.676329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.484948</td>\n",
              "      <td>0.696382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.597961</td>\n",
              "      <td>0.773280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.771281</td>\n",
              "      <td>0.878226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.437342</td>\n",
              "      <td>0.661319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.451673</td>\n",
              "      <td>0.672066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.416324</td>\n",
              "      <td>0.645232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.486135</td>\n",
              "      <td>0.697234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.441484</td>\n",
              "      <td>0.664442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.429809</td>\n",
              "      <td>0.655598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.434079</td>\n",
              "      <td>0.658847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.548327</td>\n",
              "      <td>0.740491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.443555</td>\n",
              "      <td>0.665999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.419357</td>\n",
              "      <td>0.647578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.431463</td>\n",
              "      <td>0.656858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.431135</td>\n",
              "      <td>0.656609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.468894</td>\n",
              "      <td>0.684758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.455566</td>\n",
              "      <td>0.674956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.429195</td>\n",
              "      <td>0.655129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.437492</td>\n",
              "      <td>0.661432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.440063</td>\n",
              "      <td>0.663372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.032600</td>\n",
              "      <td>0.441880</td>\n",
              "      <td>0.664740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!mkdir content wording\n",
        "for target in [\"content\", \"wording\"]:\n",
        "    train_by_fold(\n",
        "        train,\n",
        "        model_name=CFG.model_name,\n",
        "        save_each_model=True,\n",
        "        target=target,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "        num_train_epochs=CFG.num_train_epochs,\n",
        "        n_splits=CFG.n_splits,\n",
        "        batch_size=CFG.batch_size,\n",
        "        save_steps=CFG.save_steps,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-AH51-tVvXUm"
      },
      "outputs": [],
      "source": [
        "# !cp -r . /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QSQIR9klJ-bU"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  import json\n",
        "  from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "  def dataset_upload():\n",
        "      global USERID, EX_NO, UPLOAD_DIR\n",
        "      id = f'{USERID}/{EX_NO}'\n",
        "      dataset_metadata = {}\n",
        "      dataset_metadata['id'] = id\n",
        "      dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
        "      dataset_metadata['title'] = f'{TITLE}'\n",
        "      with open(UPLOAD_DIR + 'dataset-metadata.json', 'w') as f:\n",
        "          json.dump(dataset_metadata, f, indent=4)\n",
        "      api = KaggleApi()\n",
        "      api.authenticate()\n",
        "      # データセットがない場合\n",
        "      if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
        "          api.dataset_create_new(folder=UPLOAD_DIR,\n",
        "                                convert_to_csv=False,\n",
        "                                dir_mode='skip'\n",
        "                                #dir_mode='zip'\n",
        "                                )\n",
        "      # データセットがある場合\n",
        "      else:\n",
        "          api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "                                    version_notes='update',\n",
        "                                    convert_to_csv=False,\n",
        "                                    delete_old_versions=True,\n",
        "                                    dir_mode='skip'\n",
        "                                    #dir_mode='zip'\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KAY_Cyy2KEtP",
        "outputId": "bb675614-e08c-42d0-8ac9-40b3a33a32bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/another-bert/ (stored 0%)\n",
            "  adding: content/another-bert/fold_0/ (stored 0%)\n",
            "  adding: content/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_0/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_1/ (stored 0%)\n",
            "  adding: content/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_1/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_2/ (stored 0%)\n",
            "  adding: content/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_2/pytorch_model.bin (deflated 21%)\n",
            "  adding: content/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/another-bert/fold_3/ (stored 0%)\n",
            "  adding: content/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: content/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: content/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: content/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: content/another-bert/fold_3/pytorch_model.bin (deflated 22%)\n",
            "  adding: content/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: content/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/ (stored 0%)\n",
            "  adding: wording/another-bert/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_0/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_0/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_0/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_0/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_0/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_0/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_0/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_1/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_1/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_1/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_1/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_1/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_1/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_1/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_2/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_2/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_2/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_2/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_2/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_2/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_2/tokenizer_config.json (deflated 74%)\n",
            "  adding: wording/another-bert/fold_3/ (stored 0%)\n",
            "  adding: wording/another-bert/fold_3/config.json (deflated 53%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer.json (deflated 77%)\n",
            "  adding: wording/another-bert/fold_3/added_tokens.json (deflated 33%)\n",
            "  adding: wording/another-bert/fold_3/spm.model (deflated 50%)\n",
            "  adding: wording/another-bert/fold_3/pytorch_model.bin (deflated 21%)\n",
            "  adding: wording/another-bert/fold_3/special_tokens_map.json (deflated 54%)\n",
            "  adding: wording/another-bert/fold_3/tokenizer_config.json (deflated 74%)\n",
            "  adding: pickled.pkl (deflated 72%)\n",
            "CPU times: user 4.62 s, sys: 888 ms, total: 5.51 s\n",
            "Wall time: 24min 55s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl\n",
        "  # !zip -r ./tmp/output  pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uRAl0v_YKGu4",
        "outputId": "acbaabb5-b6de-4d4e-b8f5-307e3a7513cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting upload for file output.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10.2G/10.2G [01:33<00:00, 117MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: output.zip (10GB)\n",
            "CPU times: user 10.8 s, sys: 7.98 s, total: 18.8 s\n",
            "Wall time: 1min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'commitlit-deberta-v3-large-trained3'\n",
        "  EX_NO = 'commitlit-deberta-v3-large-trained3'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE56wqWxtltT"
      },
      "outputs": [],
      "source": [
        "!cp -r ./tmp /content/drive/MyDrive/Kaggle/commitlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hES5LiE3KNM6"
      },
      "source": [
        "## terminate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXEs3uuDKMG-"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64N212Z7MdTD"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    train = validate(\n",
        "        train,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )\n",
        "\n",
        "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
        "    print(f\"cv {target} rmse: {rmse}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3d_usthVu6c"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    test = predict(\n",
        "        test,\n",
        "        target=target,\n",
        "        save_each_model=True,\n",
        "        model_name=CFG.model_name,\n",
        "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
        "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
        "        max_length=CFG.max_length\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e991A_my4RXY"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWdD32Q8nws"
      },
      "source": [
        "## upload dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzr6yQHa8nBA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRl6J7Y28ySx"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   !mkdir tmp\n",
        "#   !zip -r ./tmp/output content wording pickled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWzbYTkq86KK"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# if is_colab:\n",
        "#   TITLE = 'devert-v3-trained'\n",
        "#   EX_NO = 'commitlit-2023'  # 実験番号などを入れる、folderのpathにする\n",
        "#   USERID = 'aruaru0'\n",
        "#   UPLOAD_DIR = './tmp/'\n",
        "#   dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y04vF_2m4RXY"
      },
      "source": [
        "## LGBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NFgHw004RXY"
      },
      "outputs": [],
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\"\n",
        "               ] + targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8X4hieY4RXY"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "            'boosting_type': 'gbdt',\n",
        "            'random_state': 42,\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'learning_rate': 0.048,\n",
        "            'max_depth': 3,\n",
        "            'lambda_l1': 0.0,\n",
        "            'lambda_l2': 0.011\n",
        "        }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zGTNAJKtVEf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lgbm.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4by6kkuhOx"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  !mkdir tmp\n",
        "  !zip -r ./tmp/output content wording pickled.pkl lgbm.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9XwAvJnukQL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if is_colab:\n",
        "  TITLE = 'roberta-base-trained'\n",
        "  EX_NO = 'roberta-base-trained'  # 実験番号などを入れる、folderのpathにする\n",
        "  USERID = 'aruaru0'\n",
        "  UPLOAD_DIR = './tmp/'\n",
        "  dataset_upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulmFlbGJ4RXY"
      },
      "source": [
        "## CV Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTj7OaLm4RXY"
      },
      "outputs": [],
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlVSzuh64RXY"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9NjgA4Z4RXY"
      },
      "outputs": [],
      "source": [
        "drop_columns = [\n",
        "                #\"fold\",\n",
        "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\n",
        "                \"input\"\n",
        "               ] + [\n",
        "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ] + [\n",
        "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahmlT0hs4RXY"
      },
      "outputs": [],
      "source": [
        "pred_dict = {}\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "    preds = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = test.drop(columns=drop_columns)\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "        preds.append(pred)\n",
        "\n",
        "    pred_dict[target] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Y5dzYt4RXY"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "    preds = pred_dict[target]\n",
        "    for i, pred in enumerate(preds):\n",
        "        test[f\"{target}_pred_{i}\"] = pred\n",
        "\n",
        "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqg9H2uB4RXZ"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58Z_kETy4RXZ"
      },
      "source": [
        "## Create Submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS92zy2v4RXZ"
      },
      "outputs": [],
      "source": [
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIOwTOkaHg7m"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tiflhys4RXZ"
      },
      "outputs": [],
      "source": [
        "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2sQz_YD4RXZ"
      },
      "source": [
        "## Summary\n",
        "\n",
        "CV result is like this.\n",
        "\n",
        "| | content rmse |wording rmse | mcrmse | LB| |\n",
        "| -- | -- | -- | -- | -- | -- |\n",
        "|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n",
        "| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n",
        "| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n",
        "| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n",
        "| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n",
        "\n",
        "The CV values improved slightly, and the LB value is improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8HNdBZX4RXZ"
      },
      "outputs": [],
      "source": [
        "if is_colab:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR64NiYA4RXZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx3MwlI24RXZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a93fd4a9d1a465daf3bdf056d284fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b9ae5b9399f4300bbaa9040d39d594b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bfe2a8acf204a8c9ebd9047eef7104e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d28234becb042e6a0b5bdf6f92aee7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4eb60f66d0433cafd7532f4508a70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd2b9694f1604e2c81ca3b71044fbe69",
              "IPY_MODEL_c23e5cc124e6403ebe2f79215fd60ebc",
              "IPY_MODEL_d254f17d05084fcabb003262c58447b5"
            ],
            "layout": "IPY_MODEL_7e17b21c59b44c51bda170627179cc18"
          }
        },
        "159d802be6854682aee6695ca655ea02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c549a7740c475ba98d7a3544457787",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a93fd4a9d1a465daf3bdf056d284fb8",
            "value": 2464616
          }
        },
        "1c0ea608f2bb4983936e1de0e596fd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2190d9305c4a47048e547d71d81153e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26fd2619a7ed4b2a97fe3836f71f9a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e194c8d95854cc68a65e443a8f15448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a649b271f054b7ab7b3324fc9a80450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40696edc73094d0184e9898c7d28c895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d27bd4a706a4f1f80ef2ac74ec9e7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62407ad83689406dac8820f30045af44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb76df9d1d2b41029fd00de40a415f7a",
              "IPY_MODEL_b2387e1dec8f418aa8d6b66be233de48",
              "IPY_MODEL_ced144bea4684665a7753b8b03fb45fd"
            ],
            "layout": "IPY_MODEL_e9a3907547a4467a9d4f3b0b5b3122c2"
          }
        },
        "65a5c6ab92564536acea8dad9cf31f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c82181a95c24da4967585404965b27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d8a2be01e66453c8cc260cd3a8af487": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d27bd4a706a4f1f80ef2ac74ec9e7bc",
            "placeholder": "​",
            "style": "IPY_MODEL_65a5c6ab92564536acea8dad9cf31f37",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6e598b898a5d4da39e6ed934b6503f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a6c6f67a12429aaed2505f90304a47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d38f67799e0486ca99474a27b4943f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d340babc3f004cc3abce66a84328d475",
              "IPY_MODEL_159d802be6854682aee6695ca655ea02",
              "IPY_MODEL_996e1634d09543f0b14ee40c3d461908"
            ],
            "layout": "IPY_MODEL_0d28234becb042e6a0b5bdf6f92aee7d"
          }
        },
        "7e17b21c59b44c51bda170627179cc18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c0e4aeb32c41dd97ee9c950095187b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996e1634d09543f0b14ee40c3d461908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fd2619a7ed4b2a97fe3836f71f9a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b046d34a0f45fda1671d256b6c30ec",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "9b864647d0994192b9727b9175073860": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a800ea21be7f4d638647956ceb72c85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d8a2be01e66453c8cc260cd3a8af487",
              "IPY_MODEL_fda292bad301420087d46a8e1dc52f35",
              "IPY_MODEL_f6617472aa554594b0268946475b7812"
            ],
            "layout": "IPY_MODEL_a979377ac7b54651b9415dc9f8286ddb"
          }
        },
        "a979377ac7b54651b9415dc9f8286ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2387e1dec8f418aa8d6b66be233de48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c0e4aeb32c41dd97ee9c950095187b",
            "max": 873673253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b9ae5b9399f4300bbaa9040d39d594b",
            "value": 873673253
          }
        },
        "b568f390f4a84d4ab2f6c30dc6b5dbe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b674af9681034136a8177c59c2bfb6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b717b9f6fb9340518ab51513189998e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb76df9d1d2b41029fd00de40a415f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a6c6f67a12429aaed2505f90304a47",
            "placeholder": "​",
            "style": "IPY_MODEL_e41554cdf57041b29c01f2998b9f8b40",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "bccf7f7b4ba042529a9713e0cd4e8869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c23e5cc124e6403ebe2f79215fd60ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e194c8d95854cc68a65e443a8f15448",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c0ea608f2bb4983936e1de0e596fd3e",
            "value": 580
          }
        },
        "c6b046d34a0f45fda1671d256b6c30ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2b9694f1604e2c81ca3b71044fbe69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bfe2a8acf204a8c9ebd9047eef7104e",
            "placeholder": "​",
            "style": "IPY_MODEL_2190d9305c4a47048e547d71d81153e4",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ced144bea4684665a7753b8b03fb45fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a649b271f054b7ab7b3324fc9a80450",
            "placeholder": "​",
            "style": "IPY_MODEL_9b864647d0994192b9727b9175073860",
            "value": " 874M/874M [00:13&lt;00:00, 68.3MB/s]"
          }
        },
        "d254f17d05084fcabb003262c58447b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b674af9681034136a8177c59c2bfb6a7",
            "placeholder": "​",
            "style": "IPY_MODEL_f34af6f6a4904b0fbaf1655345940587",
            "value": " 580/580 [00:00&lt;00:00, 54.2kB/s]"
          }
        },
        "d340babc3f004cc3abce66a84328d475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b717b9f6fb9340518ab51513189998e0",
            "placeholder": "​",
            "style": "IPY_MODEL_bccf7f7b4ba042529a9713e0cd4e8869",
            "value": "Downloading spm.model: 100%"
          }
        },
        "d6c549a7740c475ba98d7a3544457787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41554cdf57041b29c01f2998b9f8b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a3907547a4467a9d4f3b0b5b3122c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34af6f6a4904b0fbaf1655345940587": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6617472aa554594b0268946475b7812": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b568f390f4a84d4ab2f6c30dc6b5dbe0",
            "placeholder": "​",
            "style": "IPY_MODEL_6c82181a95c24da4967585404965b27e",
            "value": " 52.0/52.0 [00:00&lt;00:00, 4.31kB/s]"
          }
        },
        "fda292bad301420087d46a8e1dc52f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e598b898a5d4da39e6ed934b6503f7e",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40696edc73094d0184e9898c7d28c895",
            "value": 52
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}